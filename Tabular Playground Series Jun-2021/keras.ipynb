{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Importing Libraries and Datasets","metadata":{}},{"cell_type":"code","source":"import pandas as pd     \nimport matplotlib as mat\nimport matplotlib.pyplot as plt    \nimport numpy as np\nimport seaborn as sns\n%matplotlib inline\n\nimport random\nimport os\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\n\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import callbacks","metadata":{"execution":{"iopub.status.busy":"2021-09-01T08:32:47.310816Z","iopub.execute_input":"2021-09-01T08:32:47.311150Z","iopub.status.idle":"2021-09-01T08:32:52.912233Z","shell.execute_reply.started":"2021-09-01T08:32:47.311081Z","shell.execute_reply":"2021-09-01T08:32:52.911326Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#Trying to get reproducible results\nfrom numpy.random import seed\nseed(42)\nfrom tensorflow.random import set_seed\nset_seed(42)\n\nrandom.seed(42)\nos.environ['PYTHONHASHSEED'] = str(42)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T08:32:52.913725Z","iopub.execute_input":"2021-09-01T08:32:52.914076Z","iopub.status.idle":"2021-09-01T08:32:52.920247Z","shell.execute_reply.started":"2021-09-01T08:32:52.914037Z","shell.execute_reply":"2021-09-01T08:32:52.919345Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/tabular-playground-series-jun-2021/train.csv', index_col = 'id')\nY_train = df_train['target'].copy()\nX_train = df_train.copy().drop('target', axis = 1)\nX_test = pd.read_csv('../input/tabular-playground-series-jun-2021/test.csv', index_col = 'id')","metadata":{"execution":{"iopub.status.busy":"2021-09-01T08:32:52.922130Z","iopub.execute_input":"2021-09-01T08:32:52.922541Z","iopub.status.idle":"2021-09-01T08:32:55.352914Z","shell.execute_reply.started":"2021-09-01T08:32:52.922501Z","shell.execute_reply":"2021-09-01T08:32:55.352069Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class_map = {'Class_1': 0,\n            'Class_2': 1,\n            'Class_3': 2,\n            'Class_4': 3,\n            'Class_5': 4,\n            'Class_6': 5,\n            'Class_7': 6,\n            'Class_8': 7,\n            'Class_9': 8}\nY_train = Y_train.map(class_map).astype('int')\nY_train","metadata":{"execution":{"iopub.status.busy":"2021-09-01T08:32:55.354578Z","iopub.execute_input":"2021-09-01T08:32:55.354905Z","iopub.status.idle":"2021-09-01T08:32:55.388339Z","shell.execute_reply.started":"2021-09-01T08:32:55.354870Z","shell.execute_reply":"2021-09-01T08:32:55.387327Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"id\n0         5\n1         5\n2         1\n3         7\n4         1\n         ..\n199995    5\n199996    5\n199997    7\n199998    6\n199999    7\nName: target, Length: 200000, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"#Converting target series to matrix for multiclass classification on Keras\n\nY_train = to_categorical(Y_train)\nY_train","metadata":{"execution":{"iopub.status.busy":"2021-09-01T08:32:55.389589Z","iopub.execute_input":"2021-09-01T08:32:55.390150Z","iopub.status.idle":"2021-09-01T08:32:55.400688Z","shell.execute_reply.started":"2021-09-01T08:32:55.390112Z","shell.execute_reply":"2021-09-01T08:32:55.399395Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 1., 0.],\n       [0., 0., 0., ..., 1., 0., 0.],\n       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Creating and Evaluating the Wide and Deep NN","metadata":{}},{"cell_type":"code","source":"def get_wideanddeep():\n    # Wide Network\n    wide = keras.experimental.LinearModel()\n\n    # Deep Network\n    inputs = keras.Input(shape=[75])\n    x = layers.Embedding(360, 8, input_length = 75)(inputs)\n    x = layers.Conv1D(16, kernel_size=1, activation='relu')(x) #added 21/06\n    x = layers.Flatten()(x)\n    x = layers.Dropout(0.3)(x) #added 21/06\n    x = layers.Dense(units = 128, activation = 'relu')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.3)(x)\n    x = layers.Dense(units = 64, activation = 'relu')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.3)(x)\n    x = layers.Dense(units = 32, activation = 'relu')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.2)(x)\n    #outputs = layers.Dense(9, activation = 'softmax')(x)\n    outputs = layers.Dense(9)(x)\n    deep = keras.Model(inputs=inputs, outputs=outputs)\n    \n    # Wide and Deep Network\n    wide_and_deep = keras.experimental.WideDeepModel(\n        linear_model=wide,\n        dnn_model=deep,\n        activation='softmax',\n    )\n    \n    return wide_and_deep","metadata":{"execution":{"iopub.status.busy":"2021-09-01T08:32:55.402034Z","iopub.execute_input":"2021-09-01T08:32:55.402374Z","iopub.status.idle":"2021-09-01T08:32:55.412107Z","shell.execute_reply.started":"2021-09-01T08:32:55.402339Z","shell.execute_reply":"2021-09-01T08:32:55.411157Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"keras.backend.clear_session()\n\nwide_and_deep_model = get_wideanddeep()\nwide_and_deep_model.compile(loss='categorical_crossentropy', optimizer = keras.optimizers.Adam(learning_rate=0.0002), metrics='accuracy')","metadata":{"execution":{"iopub.status.busy":"2021-09-01T08:32:55.413401Z","iopub.execute_input":"2021-09-01T08:32:55.413811Z","iopub.status.idle":"2021-09-01T08:32:57.630109Z","shell.execute_reply.started":"2021-09-01T08:32:55.413777Z","shell.execute_reply":"2021-09-01T08:32:57.629230Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"X_train_split, X_val_split, Y_train_split, Y_val_split = train_test_split(X_train, Y_train, test_size = 0.2, random_state = 42\n                                                    , stratify = Y_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T08:32:57.634084Z","iopub.execute_input":"2021-09-01T08:32:57.634363Z","iopub.status.idle":"2021-09-01T08:33:00.803873Z","shell.execute_reply.started":"2021-09-01T08:32:57.634337Z","shell.execute_reply":"2021-09-01T08:33:00.803045Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"early_stopping = callbacks.EarlyStopping(\n    patience=15,\n    min_delta=0.0000001,\n    restore_best_weights=True,\n)\n\n#New callback\nplateau = callbacks.ReduceLROnPlateau(\n    factor = 0.5,                                     \n    patience = 2,                                   \n    min_delt = 0.0000001,                                \n    cooldown = 0,                               \n    verbose = 1\n) ","metadata":{"execution":{"iopub.status.busy":"2021-09-01T08:33:00.806210Z","iopub.execute_input":"2021-09-01T08:33:00.806738Z","iopub.status.idle":"2021-09-01T08:33:00.811763Z","shell.execute_reply.started":"2021-09-01T08:33:00.806698Z","shell.execute_reply":"2021-09-01T08:33:00.810865Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"history = wide_and_deep_model.fit(X_train_split, Y_train_split,                   \n          batch_size = 128, epochs = 100,\n          validation_data=(X_val_split, Y_val_split),\n          callbacks=[early_stopping, plateau]);","metadata":{"execution":{"iopub.status.busy":"2021-09-01T08:33:00.812981Z","iopub.execute_input":"2021-09-01T08:33:00.813326Z","iopub.status.idle":"2021-09-01T08:36:17.280691Z","shell.execute_reply.started":"2021-09-01T08:33:00.813289Z","shell.execute_reply":"2021-09-01T08:36:17.279708Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/100\n1250/1250 [==============================] - 11s 5ms/step - loss: 2.3996 - accuracy: 0.2112 - val_loss: 1.8194 - val_accuracy: 0.3569\nEpoch 2/100\n1250/1250 [==============================] - 6s 5ms/step - loss: 1.8774 - accuracy: 0.3296 - val_loss: 1.7609 - val_accuracy: 0.3603\nEpoch 3/100\n1250/1250 [==============================] - 6s 5ms/step - loss: 1.8015 - accuracy: 0.3472 - val_loss: 1.7545 - val_accuracy: 0.3618\nEpoch 4/100\n1250/1250 [==============================] - 7s 5ms/step - loss: 1.7803 - accuracy: 0.3522 - val_loss: 1.7512 - val_accuracy: 0.3615\nEpoch 5/100\n1250/1250 [==============================] - 6s 5ms/step - loss: 1.7734 - accuracy: 0.3540 - val_loss: 1.7529 - val_accuracy: 0.3598\nEpoch 6/100\n1250/1250 [==============================] - 6s 5ms/step - loss: 1.7703 - accuracy: 0.3529 - val_loss: 1.7491 - val_accuracy: 0.3615\nEpoch 7/100\n1250/1250 [==============================] - 6s 5ms/step - loss: 1.7612 - accuracy: 0.3572 - val_loss: 1.7486 - val_accuracy: 0.3611\nEpoch 8/100\n1250/1250 [==============================] - 6s 5ms/step - loss: 1.7618 - accuracy: 0.3575 - val_loss: 1.7494 - val_accuracy: 0.3620\nEpoch 9/100\n1250/1250 [==============================] - 6s 5ms/step - loss: 1.7583 - accuracy: 0.3603 - val_loss: 1.7481 - val_accuracy: 0.3625\nEpoch 10/100\n1250/1250 [==============================] - 6s 5ms/step - loss: 1.7605 - accuracy: 0.3579 - val_loss: 1.7478 - val_accuracy: 0.3618\nEpoch 11/100\n1250/1250 [==============================] - 6s 5ms/step - loss: 1.7522 - accuracy: 0.3602 - val_loss: 1.7476 - val_accuracy: 0.3615\nEpoch 12/100\n1250/1250 [==============================] - 6s 5ms/step - loss: 1.7589 - accuracy: 0.3588 - val_loss: 1.7475 - val_accuracy: 0.3625\nEpoch 13/100\n1250/1250 [==============================] - 6s 5ms/step - loss: 1.7512 - accuracy: 0.3597 - val_loss: 1.7468 - val_accuracy: 0.3620\nEpoch 14/100\n1250/1250 [==============================] - 6s 5ms/step - loss: 1.7466 - accuracy: 0.3626 - val_loss: 1.7474 - val_accuracy: 0.3614\nEpoch 15/100\n1250/1250 [==============================] - 6s 5ms/step - loss: 1.7499 - accuracy: 0.3619 - val_loss: 1.7468 - val_accuracy: 0.3621\n\nEpoch 00015: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\nEpoch 16/100\n1250/1250 [==============================] - 6s 5ms/step - loss: 1.7481 - accuracy: 0.3620 - val_loss: 1.7467 - val_accuracy: 0.3628\nEpoch 17/100\n1250/1250 [==============================] - 6s 5ms/step - loss: 1.7491 - accuracy: 0.3616 - val_loss: 1.7468 - val_accuracy: 0.3627\nEpoch 18/100\n1250/1250 [==============================] - 6s 5ms/step - loss: 1.7514 - accuracy: 0.3620 - val_loss: 1.7469 - val_accuracy: 0.3630\n\nEpoch 00018: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 19/100\n1250/1250 [==============================] - 6s 5ms/step - loss: 1.7468 - accuracy: 0.3616 - val_loss: 1.7470 - val_accuracy: 0.3624\nEpoch 20/100\n1250/1250 [==============================] - 7s 5ms/step - loss: 1.7460 - accuracy: 0.3608 - val_loss: 1.7470 - val_accuracy: 0.3619\n\nEpoch 00020: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 21/100\n1250/1250 [==============================] - 6s 5ms/step - loss: 1.7433 - accuracy: 0.3641 - val_loss: 1.7470 - val_accuracy: 0.3629\nEpoch 22/100\n1250/1250 [==============================] - 6s 5ms/step - loss: 1.7431 - accuracy: 0.3647 - val_loss: 1.7471 - val_accuracy: 0.3625\n\nEpoch 00022: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\nEpoch 23/100\n1250/1250 [==============================] - 6s 5ms/step - loss: 1.7447 - accuracy: 0.3639 - val_loss: 1.7470 - val_accuracy: 0.3627\nEpoch 24/100\n1250/1250 [==============================] - 6s 5ms/step - loss: 1.7411 - accuracy: 0.3632 - val_loss: 1.7470 - val_accuracy: 0.3629\n\nEpoch 00024: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\nEpoch 25/100\n1250/1250 [==============================] - 7s 5ms/step - loss: 1.7462 - accuracy: 0.3625 - val_loss: 1.7470 - val_accuracy: 0.3625\nEpoch 26/100\n1250/1250 [==============================] - 6s 5ms/step - loss: 1.7452 - accuracy: 0.3624 - val_loss: 1.7470 - val_accuracy: 0.3627\n\nEpoch 00026: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\nEpoch 27/100\n1250/1250 [==============================] - 6s 5ms/step - loss: 1.7489 - accuracy: 0.3627 - val_loss: 1.7470 - val_accuracy: 0.3626\nEpoch 28/100\n1250/1250 [==============================] - 6s 5ms/step - loss: 1.7435 - accuracy: 0.3631 - val_loss: 1.7470 - val_accuracy: 0.3625\n\nEpoch 00028: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\nEpoch 29/100\n1250/1250 [==============================] - 6s 5ms/step - loss: 1.7454 - accuracy: 0.3656 - val_loss: 1.7470 - val_accuracy: 0.3626\nEpoch 30/100\n1250/1250 [==============================] - 6s 5ms/step - loss: 1.7438 - accuracy: 0.3629 - val_loss: 1.7470 - val_accuracy: 0.3624\n\nEpoch 00030: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\nEpoch 31/100\n1250/1250 [==============================] - 6s 5ms/step - loss: 1.7440 - accuracy: 0.3639 - val_loss: 1.7470 - val_accuracy: 0.3626\n","output_type":"stream"}]},{"cell_type":"code","source":"score = wide_and_deep_model.evaluate(X_val_split, Y_val_split, verbose = 0)\nprint('Test loss: {}'.format(score[0]))\nprint('Test accuracy: {}%'.format(score[1] * 100))","metadata":{"execution":{"iopub.status.busy":"2021-09-01T08:36:17.282140Z","iopub.execute_input":"2021-09-01T08:36:17.282564Z","iopub.status.idle":"2021-09-01T08:36:19.795721Z","shell.execute_reply.started":"2021-09-01T08:36:17.282521Z","shell.execute_reply":"2021-09-01T08:36:19.794897Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Test loss: 1.7467145919799805\nTest accuracy: 36.28250062465668%\n","output_type":"stream"}]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,8))\nsns.lineplot(x = history.epoch, y = history.history['loss'])\nsns.lineplot(x = history.epoch, y = history.history['val_loss'])\nax.set_title('Learning Curve (Loss)')\nax.set_ylabel('Loss')\nax.set_xlabel('Epoch')\nax.legend(['train', 'test'], loc='best')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-01T08:36:19.797071Z","iopub.execute_input":"2021-09-01T08:36:19.797398Z","iopub.status.idle":"2021-09-01T08:36:20.026987Z","shell.execute_reply.started":"2021-09-01T08:36:19.797362Z","shell.execute_reply":"2021-09-01T08:36:20.026027Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1440x576 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"## Making Predictions","metadata":{}},{"cell_type":"code","source":"Y_train = df_train['target'].copy()\nY_train = Y_train.map(class_map).astype('int')\nY_train","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-09-01T08:36:20.028201Z","iopub.execute_input":"2021-09-01T08:36:20.028529Z","iopub.status.idle":"2021-09-01T08:36:20.059765Z","shell.execute_reply.started":"2021-09-01T08:36:20.028490Z","shell.execute_reply":"2021-09-01T08:36:20.058831Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"id\n0         5\n1         5\n2         1\n3         7\n4         1\n         ..\n199995    5\n199996    5\n199997    7\n199998    6\n199999    7\nName: target, Length: 200000, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"def prediction (X_train, Y_train, X_test):\n    \n    keras.backend.clear_session()\n\n    kfold = StratifiedKFold(n_splits = 25)\n\n    y_pred = np.zeros((100000,9))\n    train_oof = np.zeros((200000,9))\n    \n    for idx in kfold.split(X=X_train, y=Y_train):\n        train_idx, val_idx = idx[0], idx[1]\n        xtrain = X_train.iloc[train_idx]\n        ytrain = Y_train.iloc[train_idx]\n        xval = X_train.iloc[val_idx]\n        yval = Y_train.iloc[val_idx]\n        \n        ytrain = to_categorical(ytrain)\n        yval = to_categorical(yval)\n        \n        # fit model for current fold\n        wide_and_deep_model = get_wideanddeep()\n        wide_and_deep_model.compile(loss='categorical_crossentropy', optimizer = keras.optimizers.Adam(learning_rate=0.0002), metrics='accuracy')\n        \n        wide_and_deep_model.fit(xtrain, ytrain,\n        batch_size = 128, epochs = 100,\n        validation_data=(xval, yval),\n        callbacks=[early_stopping, plateau]);\n\n        #create predictions\n        y_pred += wide_and_deep_model.predict(X_test)/kfold.n_splits\n        print(y_pred)\n               \n        val_pred = wide_and_deep_model.predict(xval)\n        # getting out-of-fold predictions on training set\n        train_oof[val_idx] = val_pred\n        \n        # calculate and append logloss\n        fold_logloss = metrics.log_loss(yval,val_pred)\n        print(\"Logloss: {0:0.5f}\". format(fold_logloss))\n  \n    return y_pred, train_oof","metadata":{"execution":{"iopub.status.busy":"2021-09-01T08:36:20.061049Z","iopub.execute_input":"2021-09-01T08:36:20.061394Z","iopub.status.idle":"2021-09-01T08:36:20.070833Z","shell.execute_reply.started":"2021-09-01T08:36:20.061358Z","shell.execute_reply":"2021-09-01T08:36:20.070007Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"nn_pred, train_oof = prediction (X_train, Y_train, X_test)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-09-01T08:36:20.072341Z","iopub.execute_input":"2021-09-01T08:36:20.073048Z","iopub.status.idle":"2021-09-01T10:08:53.743742Z","shell.execute_reply.started":"2021-09-01T08:36:20.073004Z","shell.execute_reply":"2021-09-01T10:08:53.742819Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Epoch 1/100\n1500/1500 [==============================] - 8s 5ms/step - loss: 2.3950 - accuracy: 0.2249 - val_loss: 1.7914 - val_accuracy: 0.3525\nEpoch 2/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.8492 - accuracy: 0.3349 - val_loss: 1.7529 - val_accuracy: 0.3601\nEpoch 3/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7933 - accuracy: 0.3491 - val_loss: 1.7491 - val_accuracy: 0.3598\nEpoch 4/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7783 - accuracy: 0.3527 - val_loss: 1.7475 - val_accuracy: 0.3605\nEpoch 5/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7683 - accuracy: 0.3574 - val_loss: 1.7490 - val_accuracy: 0.3591\nEpoch 6/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7600 - accuracy: 0.3592 - val_loss: 1.7486 - val_accuracy: 0.3581\n\nEpoch 00006: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\nEpoch 7/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7574 - accuracy: 0.3581 - val_loss: 1.7456 - val_accuracy: 0.3605\nEpoch 8/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7573 - accuracy: 0.3593 - val_loss: 1.7451 - val_accuracy: 0.3590\nEpoch 9/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7573 - accuracy: 0.3570 - val_loss: 1.7451 - val_accuracy: 0.3609\nEpoch 10/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7547 - accuracy: 0.3614 - val_loss: 1.7455 - val_accuracy: 0.3594\n\nEpoch 00010: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 11/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7537 - accuracy: 0.3596 - val_loss: 1.7448 - val_accuracy: 0.3581\nEpoch 12/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7509 - accuracy: 0.3636 - val_loss: 1.7450 - val_accuracy: 0.3587\nEpoch 13/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7534 - accuracy: 0.3621 - val_loss: 1.7452 - val_accuracy: 0.3593\n\nEpoch 00013: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 14/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7490 - accuracy: 0.3633 - val_loss: 1.7451 - val_accuracy: 0.3577\nEpoch 15/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7490 - accuracy: 0.3624 - val_loss: 1.7450 - val_accuracy: 0.3580\n\nEpoch 00015: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\nEpoch 16/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7537 - accuracy: 0.3611 - val_loss: 1.7448 - val_accuracy: 0.3593\nEpoch 17/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7522 - accuracy: 0.3608 - val_loss: 1.7449 - val_accuracy: 0.3582\n\nEpoch 00017: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\nEpoch 18/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7501 - accuracy: 0.3623 - val_loss: 1.7449 - val_accuracy: 0.3584\nEpoch 19/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7497 - accuracy: 0.3595 - val_loss: 1.7448 - val_accuracy: 0.3590\n\nEpoch 00019: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\nEpoch 20/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7529 - accuracy: 0.3588 - val_loss: 1.7448 - val_accuracy: 0.3577\nEpoch 21/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7540 - accuracy: 0.3616 - val_loss: 1.7448 - val_accuracy: 0.3582\n\nEpoch 00021: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\nEpoch 22/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7536 - accuracy: 0.3607 - val_loss: 1.7448 - val_accuracy: 0.3585\nEpoch 23/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7548 - accuracy: 0.3589 - val_loss: 1.7447 - val_accuracy: 0.3579\n\nEpoch 00023: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\nEpoch 24/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7500 - accuracy: 0.3632 - val_loss: 1.7448 - val_accuracy: 0.3581\nEpoch 25/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7559 - accuracy: 0.3596 - val_loss: 1.7448 - val_accuracy: 0.3585\n\nEpoch 00025: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\nEpoch 26/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7521 - accuracy: 0.3609 - val_loss: 1.7448 - val_accuracy: 0.3580\nEpoch 27/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7516 - accuracy: 0.3628 - val_loss: 1.7448 - val_accuracy: 0.3577\n\nEpoch 00027: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\nEpoch 28/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7522 - accuracy: 0.3610 - val_loss: 1.7448 - val_accuracy: 0.3587\nEpoch 29/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7480 - accuracy: 0.3616 - val_loss: 1.7447 - val_accuracy: 0.3582\nEpoch 30/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7508 - accuracy: 0.3634 - val_loss: 1.7448 - val_accuracy: 0.3577\nEpoch 31/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7501 - accuracy: 0.3621 - val_loss: 1.7448 - val_accuracy: 0.3579\n\nEpoch 00031: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\nEpoch 32/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7501 - accuracy: 0.3612 - val_loss: 1.7447 - val_accuracy: 0.3582\nEpoch 33/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7557 - accuracy: 0.3607 - val_loss: 1.7449 - val_accuracy: 0.3581\n\nEpoch 00033: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\nEpoch 34/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7537 - accuracy: 0.3620 - val_loss: 1.7447 - val_accuracy: 0.3580\nEpoch 35/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7510 - accuracy: 0.3620 - val_loss: 1.7449 - val_accuracy: 0.3585\n\nEpoch 00035: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\nEpoch 36/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7508 - accuracy: 0.3620 - val_loss: 1.7449 - val_accuracy: 0.3579\nEpoch 37/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7509 - accuracy: 0.3621 - val_loss: 1.7447 - val_accuracy: 0.3585\n\nEpoch 00037: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\nEpoch 38/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7509 - accuracy: 0.3620 - val_loss: 1.7449 - val_accuracy: 0.3585\nEpoch 39/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7490 - accuracy: 0.3629 - val_loss: 1.7448 - val_accuracy: 0.3579\n\nEpoch 00039: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\nEpoch 40/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7514 - accuracy: 0.3628 - val_loss: 1.7448 - val_accuracy: 0.3580\nEpoch 41/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7497 - accuracy: 0.3636 - val_loss: 1.7449 - val_accuracy: 0.3575\n\nEpoch 00041: ReduceLROnPlateau reducing learning rate to 3.051757735406113e-09.\nEpoch 42/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7517 - accuracy: 0.3627 - val_loss: 1.7448 - val_accuracy: 0.3573\nEpoch 43/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7514 - accuracy: 0.3628 - val_loss: 1.7448 - val_accuracy: 0.3582\n\nEpoch 00043: ReduceLROnPlateau reducing learning rate to 1.5258788677030566e-09.\nEpoch 44/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7525 - accuracy: 0.3610 - val_loss: 1.7447 - val_accuracy: 0.3587\n[[0.00240189 0.01590756 0.00632963 ... 0.0009237  0.00193003 0.00520253]\n [0.00170235 0.00248287 0.00197239 ... 0.00345096 0.01231079 0.00517587]\n [0.00073591 0.00110765 0.00069715 ... 0.00097459 0.00420562 0.00176198]\n ...\n [0.00223745 0.00858506 0.00484191 ... 0.00214836 0.00562308 0.00650965]\n [0.00145231 0.00091009 0.0008508  ... 0.00332609 0.0148999  0.00340917]\n [0.00182069 0.00362994 0.00270203 ... 0.00325198 0.01025759 0.00573119]]\nLogloss: 1.74470\nEpoch 1/100\n1500/1500 [==============================] - 8s 5ms/step - loss: 2.3604 - accuracy: 0.2185 - val_loss: 1.7869 - val_accuracy: 0.3550\nEpoch 2/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.8462 - accuracy: 0.3308 - val_loss: 1.7475 - val_accuracy: 0.3610\nEpoch 3/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7921 - accuracy: 0.3479 - val_loss: 1.7443 - val_accuracy: 0.3585\nEpoch 4/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7777 - accuracy: 0.3511 - val_loss: 1.7434 - val_accuracy: 0.3602\nEpoch 5/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7669 - accuracy: 0.3586 - val_loss: 1.7423 - val_accuracy: 0.3620\nEpoch 6/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7606 - accuracy: 0.3584 - val_loss: 1.7411 - val_accuracy: 0.3640\nEpoch 7/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7591 - accuracy: 0.3588 - val_loss: 1.7395 - val_accuracy: 0.3621\nEpoch 8/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7603 - accuracy: 0.3582 - val_loss: 1.7393 - val_accuracy: 0.3625\nEpoch 9/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7579 - accuracy: 0.3576 - val_loss: 1.7394 - val_accuracy: 0.3626\nEpoch 10/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7553 - accuracy: 0.3613 - val_loss: 1.7398 - val_accuracy: 0.3621\n\nEpoch 00010: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\nEpoch 11/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7529 - accuracy: 0.3595 - val_loss: 1.7387 - val_accuracy: 0.3619\nEpoch 12/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7515 - accuracy: 0.3620 - val_loss: 1.7380 - val_accuracy: 0.3604\nEpoch 13/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7533 - accuracy: 0.3622 - val_loss: 1.7371 - val_accuracy: 0.3629\nEpoch 14/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7505 - accuracy: 0.3626 - val_loss: 1.7375 - val_accuracy: 0.3605\nEpoch 15/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7479 - accuracy: 0.3616 - val_loss: 1.7407 - val_accuracy: 0.3614\n\nEpoch 00015: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 16/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7527 - accuracy: 0.3622 - val_loss: 1.7370 - val_accuracy: 0.3613\nEpoch 17/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7510 - accuracy: 0.3600 - val_loss: 1.7371 - val_accuracy: 0.3610\nEpoch 18/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7484 - accuracy: 0.3622 - val_loss: 1.7367 - val_accuracy: 0.3613\nEpoch 19/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7493 - accuracy: 0.3599 - val_loss: 1.7370 - val_accuracy: 0.3626\nEpoch 20/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7504 - accuracy: 0.3604 - val_loss: 1.7371 - val_accuracy: 0.3614\n\nEpoch 00020: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 21/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7504 - accuracy: 0.3609 - val_loss: 1.7365 - val_accuracy: 0.3638\nEpoch 22/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7521 - accuracy: 0.3617 - val_loss: 1.7366 - val_accuracy: 0.3624\nEpoch 23/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7528 - accuracy: 0.3612 - val_loss: 1.7364 - val_accuracy: 0.3629\nEpoch 24/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7472 - accuracy: 0.3631 - val_loss: 1.7367 - val_accuracy: 0.3620\nEpoch 25/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7530 - accuracy: 0.3613 - val_loss: 1.7366 - val_accuracy: 0.3634\n\nEpoch 00025: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\nEpoch 26/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7497 - accuracy: 0.3603 - val_loss: 1.7369 - val_accuracy: 0.3618\nEpoch 27/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7495 - accuracy: 0.3638 - val_loss: 1.7368 - val_accuracy: 0.3632\n\nEpoch 00027: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\nEpoch 28/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7492 - accuracy: 0.3612 - val_loss: 1.7367 - val_accuracy: 0.3632\nEpoch 29/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7446 - accuracy: 0.3628 - val_loss: 1.7366 - val_accuracy: 0.3615\n\nEpoch 00029: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\nEpoch 30/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7468 - accuracy: 0.3632 - val_loss: 1.7365 - val_accuracy: 0.3613\nEpoch 31/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7477 - accuracy: 0.3623 - val_loss: 1.7366 - val_accuracy: 0.3610\n\nEpoch 00031: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\nEpoch 32/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7465 - accuracy: 0.3618 - val_loss: 1.7366 - val_accuracy: 0.3613\nEpoch 33/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7525 - accuracy: 0.3615 - val_loss: 1.7367 - val_accuracy: 0.3609\n\nEpoch 00033: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\nEpoch 34/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7518 - accuracy: 0.3608 - val_loss: 1.7367 - val_accuracy: 0.3615\nEpoch 35/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7487 - accuracy: 0.3627 - val_loss: 1.7369 - val_accuracy: 0.3613\n\nEpoch 00035: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\nEpoch 36/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7484 - accuracy: 0.3617 - val_loss: 1.7366 - val_accuracy: 0.3618\nEpoch 37/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7472 - accuracy: 0.3632 - val_loss: 1.7368 - val_accuracy: 0.3614\n\nEpoch 00037: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\nEpoch 38/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7495 - accuracy: 0.3637 - val_loss: 1.7367 - val_accuracy: 0.3619\n[[0.00498306 0.03290896 0.01269706 ... 0.00175588 0.00365912 0.01000985]\n [0.00347198 0.00526938 0.00418531 ... 0.00693681 0.02439057 0.0105335 ]\n [0.00142075 0.00201723 0.00131763 ... 0.00174439 0.00776979 0.00324808]\n ...\n [0.00437323 0.01696206 0.00966684 ... 0.00438968 0.01160808 0.01310794]\n [0.00290176 0.00196865 0.00179247 ... 0.00668435 0.02998285 0.00712798]\n [0.00382204 0.00767117 0.00581025 ... 0.00662306 0.0198427  0.01174814]]\nLogloss: 1.73639\nEpoch 1/100\n1500/1500 [==============================] - 8s 4ms/step - loss: 2.4047 - accuracy: 0.2070 - val_loss: 1.7951 - val_accuracy: 0.3570\nEpoch 2/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.8610 - accuracy: 0.3288 - val_loss: 1.7574 - val_accuracy: 0.3613\nEpoch 3/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7956 - accuracy: 0.3479 - val_loss: 1.7496 - val_accuracy: 0.3602\nEpoch 4/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7791 - accuracy: 0.3531 - val_loss: 1.7479 - val_accuracy: 0.3640\nEpoch 5/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7688 - accuracy: 0.3589 - val_loss: 1.7476 - val_accuracy: 0.3634\nEpoch 6/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7640 - accuracy: 0.3587 - val_loss: 1.7471 - val_accuracy: 0.3621\nEpoch 7/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7591 - accuracy: 0.3592 - val_loss: 1.7430 - val_accuracy: 0.3677\nEpoch 8/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7599 - accuracy: 0.3578 - val_loss: 1.7432 - val_accuracy: 0.3623\nEpoch 9/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7587 - accuracy: 0.3572 - val_loss: 1.7439 - val_accuracy: 0.3625\n\nEpoch 00009: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\nEpoch 10/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7555 - accuracy: 0.3616 - val_loss: 1.7429 - val_accuracy: 0.3631\nEpoch 11/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7533 - accuracy: 0.3599 - val_loss: 1.7429 - val_accuracy: 0.3620\n\nEpoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 12/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7524 - accuracy: 0.3628 - val_loss: 1.7424 - val_accuracy: 0.3625\nEpoch 13/100\n1500/1500 [==============================] - 8s 5ms/step - loss: 1.7552 - accuracy: 0.3598 - val_loss: 1.7427 - val_accuracy: 0.3640\nEpoch 14/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7518 - accuracy: 0.3610 - val_loss: 1.7425 - val_accuracy: 0.3629\n\nEpoch 00014: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 15/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7488 - accuracy: 0.3615 - val_loss: 1.7428 - val_accuracy: 0.3624\nEpoch 16/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7545 - accuracy: 0.3600 - val_loss: 1.7423 - val_accuracy: 0.3635\nEpoch 17/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7531 - accuracy: 0.3615 - val_loss: 1.7424 - val_accuracy: 0.3625\nEpoch 18/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7503 - accuracy: 0.3626 - val_loss: 1.7423 - val_accuracy: 0.3626\n\nEpoch 00018: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\nEpoch 19/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7503 - accuracy: 0.3609 - val_loss: 1.7425 - val_accuracy: 0.3630\nEpoch 20/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7507 - accuracy: 0.3611 - val_loss: 1.7425 - val_accuracy: 0.3611\n\nEpoch 00020: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\nEpoch 21/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7531 - accuracy: 0.3622 - val_loss: 1.7423 - val_accuracy: 0.3624\nEpoch 22/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7532 - accuracy: 0.3614 - val_loss: 1.7423 - val_accuracy: 0.3624\n\nEpoch 00022: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\nEpoch 23/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7540 - accuracy: 0.3595 - val_loss: 1.7423 - val_accuracy: 0.3620\nEpoch 24/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7491 - accuracy: 0.3635 - val_loss: 1.7423 - val_accuracy: 0.3626\n\nEpoch 00024: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\nEpoch 25/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7536 - accuracy: 0.3604 - val_loss: 1.7424 - val_accuracy: 0.3623\nEpoch 26/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7515 - accuracy: 0.3602 - val_loss: 1.7424 - val_accuracy: 0.3623\n\nEpoch 00026: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\nEpoch 27/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7517 - accuracy: 0.3634 - val_loss: 1.7424 - val_accuracy: 0.3627\nEpoch 28/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7513 - accuracy: 0.3614 - val_loss: 1.7423 - val_accuracy: 0.3626\n\nEpoch 00028: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\nEpoch 29/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7472 - accuracy: 0.3639 - val_loss: 1.7423 - val_accuracy: 0.3620\nEpoch 30/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7502 - accuracy: 0.3632 - val_loss: 1.7423 - val_accuracy: 0.3621\n\nEpoch 00030: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\nEpoch 31/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7518 - accuracy: 0.3620 - val_loss: 1.7424 - val_accuracy: 0.3623\nEpoch 32/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7488 - accuracy: 0.3626 - val_loss: 1.7423 - val_accuracy: 0.3626\n\nEpoch 00032: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\nEpoch 33/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7563 - accuracy: 0.3600 - val_loss: 1.7424 - val_accuracy: 0.3621\nEpoch 34/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7546 - accuracy: 0.3595 - val_loss: 1.7423 - val_accuracy: 0.3627\n\nEpoch 00034: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\nEpoch 35/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7521 - accuracy: 0.3613 - val_loss: 1.7425 - val_accuracy: 0.3625\nEpoch 36/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7491 - accuracy: 0.3628 - val_loss: 1.7423 - val_accuracy: 0.3619\n\nEpoch 00036: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\nEpoch 37/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7513 - accuracy: 0.3644 - val_loss: 1.7424 - val_accuracy: 0.3627\nEpoch 38/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7516 - accuracy: 0.3624 - val_loss: 1.7424 - val_accuracy: 0.3626\n\nEpoch 00038: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n[[0.00748087 0.04907832 0.0190893  ... 0.00264251 0.00555786 0.01507434]\n [0.00522813 0.00790097 0.0063366  ... 0.01049669 0.03678722 0.01580936]\n [0.00219861 0.00298145 0.00198678 ... 0.00265904 0.01191737 0.00489191]\n ...\n [0.00670271 0.02714649 0.01499418 ... 0.00627533 0.01639913 0.01946469]\n [0.00426817 0.00290084 0.00262186 ... 0.00999127 0.04564729 0.01052611]\n [0.00569703 0.01113546 0.00862464 ... 0.00999382 0.02994398 0.01740121]]\nLogloss: 1.74227\nEpoch 1/100\n1500/1500 [==============================] - 8s 5ms/step - loss: 2.3218 - accuracy: 0.2293 - val_loss: 1.7844 - val_accuracy: 0.3618\nEpoch 2/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.8398 - accuracy: 0.3394 - val_loss: 1.7528 - val_accuracy: 0.3621\nEpoch 3/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7892 - accuracy: 0.3515 - val_loss: 1.7488 - val_accuracy: 0.3627\nEpoch 4/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7754 - accuracy: 0.3543 - val_loss: 1.7467 - val_accuracy: 0.3660\nEpoch 5/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7650 - accuracy: 0.3590 - val_loss: 1.7479 - val_accuracy: 0.3664\nEpoch 6/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7592 - accuracy: 0.3583 - val_loss: 1.7488 - val_accuracy: 0.3610\n\nEpoch 00006: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\nEpoch 7/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7572 - accuracy: 0.3602 - val_loss: 1.7455 - val_accuracy: 0.3643\nEpoch 8/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7583 - accuracy: 0.3589 - val_loss: 1.7452 - val_accuracy: 0.3654\nEpoch 9/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7569 - accuracy: 0.3592 - val_loss: 1.7459 - val_accuracy: 0.3641\nEpoch 10/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7542 - accuracy: 0.3619 - val_loss: 1.7449 - val_accuracy: 0.3624\nEpoch 11/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7541 - accuracy: 0.3598 - val_loss: 1.7455 - val_accuracy: 0.3671\nEpoch 12/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7513 - accuracy: 0.3632 - val_loss: 1.7458 - val_accuracy: 0.3665\n\nEpoch 00012: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 13/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7525 - accuracy: 0.3610 - val_loss: 1.7455 - val_accuracy: 0.3660\nEpoch 14/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7506 - accuracy: 0.3626 - val_loss: 1.7454 - val_accuracy: 0.3672\n\nEpoch 00014: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 15/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7475 - accuracy: 0.3614 - val_loss: 1.7459 - val_accuracy: 0.3659\nEpoch 16/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7522 - accuracy: 0.3608 - val_loss: 1.7454 - val_accuracy: 0.3658\n\nEpoch 00016: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\nEpoch 17/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7511 - accuracy: 0.3605 - val_loss: 1.7455 - val_accuracy: 0.3654\nEpoch 18/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7501 - accuracy: 0.3630 - val_loss: 1.7452 - val_accuracy: 0.3655\n\nEpoch 00018: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\nEpoch 19/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7499 - accuracy: 0.3618 - val_loss: 1.7452 - val_accuracy: 0.3655\nEpoch 20/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7508 - accuracy: 0.3598 - val_loss: 1.7454 - val_accuracy: 0.3658\n\nEpoch 00020: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\nEpoch 21/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7518 - accuracy: 0.3638 - val_loss: 1.7453 - val_accuracy: 0.3654\nEpoch 22/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7515 - accuracy: 0.3617 - val_loss: 1.7453 - val_accuracy: 0.3654\n\nEpoch 00022: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\nEpoch 23/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7520 - accuracy: 0.3619 - val_loss: 1.7453 - val_accuracy: 0.3652\nEpoch 24/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7494 - accuracy: 0.3621 - val_loss: 1.7453 - val_accuracy: 0.3656\n\nEpoch 00024: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\nEpoch 25/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7526 - accuracy: 0.3612 - val_loss: 1.7453 - val_accuracy: 0.3656\n[[0.01004731 0.06480338 0.02572122 ... 0.00354248 0.00752178 0.02012619]\n [0.00697498 0.01036039 0.00832621 ... 0.01390438 0.04924853 0.02089672]\n [0.00289661 0.00406749 0.00269058 ... 0.00366897 0.01661551 0.00668111]\n ...\n [0.00900285 0.03674562 0.02024678 ... 0.0083557  0.02164963 0.025775  ]\n [0.00569951 0.00386482 0.00346711 ... 0.01330745 0.060695   0.01397157]\n [0.00754759 0.01510304 0.01170274 ... 0.01326496 0.03967421 0.02320619]]\nLogloss: 1.74493\nEpoch 1/100\n1500/1500 [==============================] - 8s 5ms/step - loss: 2.3492 - accuracy: 0.2190 - val_loss: 1.7863 - val_accuracy: 0.3554\nEpoch 2/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.8398 - accuracy: 0.3352 - val_loss: 1.7543 - val_accuracy: 0.3596\nEpoch 3/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7905 - accuracy: 0.3468 - val_loss: 1.7524 - val_accuracy: 0.3575\nEpoch 4/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7761 - accuracy: 0.3534 - val_loss: 1.7501 - val_accuracy: 0.3599\nEpoch 5/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7665 - accuracy: 0.3599 - val_loss: 1.7499 - val_accuracy: 0.3590\nEpoch 6/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7606 - accuracy: 0.3579 - val_loss: 1.7493 - val_accuracy: 0.3576\nEpoch 7/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7578 - accuracy: 0.3594 - val_loss: 1.7490 - val_accuracy: 0.3586\nEpoch 8/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7585 - accuracy: 0.3587 - val_loss: 1.7482 - val_accuracy: 0.3589\nEpoch 9/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7564 - accuracy: 0.3580 - val_loss: 1.7492 - val_accuracy: 0.3599\nEpoch 10/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7529 - accuracy: 0.3629 - val_loss: 1.7490 - val_accuracy: 0.3593\n\nEpoch 00010: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\nEpoch 11/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7524 - accuracy: 0.3599 - val_loss: 1.7478 - val_accuracy: 0.3586\nEpoch 12/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7511 - accuracy: 0.3631 - val_loss: 1.7485 - val_accuracy: 0.3594\nEpoch 13/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7529 - accuracy: 0.3615 - val_loss: 1.7483 - val_accuracy: 0.3596\n\nEpoch 00013: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 14/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7495 - accuracy: 0.3637 - val_loss: 1.7483 - val_accuracy: 0.3581\nEpoch 15/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7464 - accuracy: 0.3641 - val_loss: 1.7483 - val_accuracy: 0.3591\n\nEpoch 00015: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 16/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7508 - accuracy: 0.3618 - val_loss: 1.7483 - val_accuracy: 0.3581\nEpoch 17/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7501 - accuracy: 0.3617 - val_loss: 1.7483 - val_accuracy: 0.3575\n\nEpoch 00017: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\nEpoch 18/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7489 - accuracy: 0.3630 - val_loss: 1.7484 - val_accuracy: 0.3585\nEpoch 19/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7483 - accuracy: 0.3613 - val_loss: 1.7484 - val_accuracy: 0.3570\n\nEpoch 00019: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\nEpoch 20/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7496 - accuracy: 0.3595 - val_loss: 1.7484 - val_accuracy: 0.3576\nEpoch 21/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7508 - accuracy: 0.3644 - val_loss: 1.7484 - val_accuracy: 0.3576\n\nEpoch 00021: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\nEpoch 22/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7511 - accuracy: 0.3615 - val_loss: 1.7484 - val_accuracy: 0.3575\nEpoch 23/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7517 - accuracy: 0.3622 - val_loss: 1.7484 - val_accuracy: 0.3571\n\nEpoch 00023: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\nEpoch 24/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7472 - accuracy: 0.3617 - val_loss: 1.7485 - val_accuracy: 0.3562\nEpoch 25/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7529 - accuracy: 0.3597 - val_loss: 1.7484 - val_accuracy: 0.3570\n\nEpoch 00025: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\nEpoch 26/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7490 - accuracy: 0.3613 - val_loss: 1.7484 - val_accuracy: 0.3569\n[[0.01263072 0.08174903 0.03221791 ... 0.00441508 0.00925175 0.0250786 ]\n [0.00873488 0.01278429 0.01028415 ... 0.01743695 0.06207664 0.02597645]\n [0.00368284 0.00516592 0.00351467 ... 0.00478833 0.02166368 0.0085935 ]\n ...\n [0.01133533 0.04591358 0.02527211 ... 0.01046604 0.02687012 0.03216117]\n [0.00714469 0.00497101 0.00440766 ... 0.0166985  0.0758946  0.01764919]\n [0.00931603 0.0185856  0.01436889 ... 0.01646066 0.05030486 0.02891148]]\nLogloss: 1.74779\nEpoch 1/100\n1500/1500 [==============================] - 8s 5ms/step - loss: 2.3725 - accuracy: 0.2121 - val_loss: 1.7920 - val_accuracy: 0.3600\nEpoch 2/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.8570 - accuracy: 0.3318 - val_loss: 1.7535 - val_accuracy: 0.3630\nEpoch 3/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7939 - accuracy: 0.3475 - val_loss: 1.7495 - val_accuracy: 0.3645\nEpoch 4/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7782 - accuracy: 0.3515 - val_loss: 1.7447 - val_accuracy: 0.3624\nEpoch 5/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7685 - accuracy: 0.3570 - val_loss: 1.7438 - val_accuracy: 0.3616\nEpoch 6/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7608 - accuracy: 0.3576 - val_loss: 1.7433 - val_accuracy: 0.3639\nEpoch 7/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7587 - accuracy: 0.3602 - val_loss: 1.7469 - val_accuracy: 0.3626\nEpoch 8/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7600 - accuracy: 0.3595 - val_loss: 1.7415 - val_accuracy: 0.3629\nEpoch 9/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7575 - accuracy: 0.3579 - val_loss: 1.7416 - val_accuracy: 0.3629\nEpoch 10/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7522 - accuracy: 0.3630 - val_loss: 1.7423 - val_accuracy: 0.3636\n\nEpoch 00010: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\nEpoch 11/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7526 - accuracy: 0.3601 - val_loss: 1.7407 - val_accuracy: 0.3636\nEpoch 12/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7519 - accuracy: 0.3619 - val_loss: 1.7409 - val_accuracy: 0.3644\nEpoch 13/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7538 - accuracy: 0.3594 - val_loss: 1.7403 - val_accuracy: 0.3643\nEpoch 14/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7518 - accuracy: 0.3612 - val_loss: 1.7410 - val_accuracy: 0.3651\nEpoch 15/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7484 - accuracy: 0.3617 - val_loss: 1.7457 - val_accuracy: 0.3659\n\nEpoch 00015: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 16/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7518 - accuracy: 0.3607 - val_loss: 1.7409 - val_accuracy: 0.3643\nEpoch 17/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7507 - accuracy: 0.3607 - val_loss: 1.7415 - val_accuracy: 0.3647\n\nEpoch 00017: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 18/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7500 - accuracy: 0.3630 - val_loss: 1.7412 - val_accuracy: 0.3651\nEpoch 19/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7487 - accuracy: 0.3610 - val_loss: 1.7413 - val_accuracy: 0.3651\n\nEpoch 00019: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\nEpoch 20/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7507 - accuracy: 0.3592 - val_loss: 1.7411 - val_accuracy: 0.3644\nEpoch 21/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7519 - accuracy: 0.3631 - val_loss: 1.7412 - val_accuracy: 0.3651\n\nEpoch 00021: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\nEpoch 22/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7522 - accuracy: 0.3613 - val_loss: 1.7412 - val_accuracy: 0.3651\nEpoch 23/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7524 - accuracy: 0.3601 - val_loss: 1.7408 - val_accuracy: 0.3652\n\nEpoch 00023: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\nEpoch 24/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7471 - accuracy: 0.3628 - val_loss: 1.7409 - val_accuracy: 0.3652\nEpoch 25/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7527 - accuracy: 0.3603 - val_loss: 1.7410 - val_accuracy: 0.3647\n\nEpoch 00025: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\nEpoch 26/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7483 - accuracy: 0.3601 - val_loss: 1.7410 - val_accuracy: 0.3650\nEpoch 27/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7512 - accuracy: 0.3622 - val_loss: 1.7412 - val_accuracy: 0.3650\n\nEpoch 00027: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\nEpoch 28/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7487 - accuracy: 0.3620 - val_loss: 1.7411 - val_accuracy: 0.3654\n[[0.01508341 0.09869553 0.0386959  ... 0.00522621 0.01096786 0.02996104]\n [0.01047528 0.01530239 0.01229453 ... 0.02101722 0.07446641 0.03115285]\n [0.00441806 0.00616131 0.0041017  ... 0.00559085 0.02506394 0.01013771]\n ...\n [0.01367493 0.05465809 0.03022699 ... 0.01265492 0.03233008 0.03861419]\n [0.00858183 0.00604067 0.00530799 ... 0.02013071 0.09106034 0.02130175]\n [0.01110088 0.02256021 0.01725194 ... 0.01964126 0.0602616  0.03477062]]\nLogloss: 1.74025\nEpoch 1/100\n1500/1500 [==============================] - 8s 5ms/step - loss: 2.3518 - accuracy: 0.2299 - val_loss: 1.7691 - val_accuracy: 0.3594\nEpoch 2/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.8408 - accuracy: 0.3352 - val_loss: 1.7423 - val_accuracy: 0.3580\nEpoch 3/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7913 - accuracy: 0.3494 - val_loss: 1.7378 - val_accuracy: 0.3619\nEpoch 4/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7791 - accuracy: 0.3519 - val_loss: 1.7365 - val_accuracy: 0.3600\nEpoch 5/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7665 - accuracy: 0.3590 - val_loss: 1.7344 - val_accuracy: 0.3590\nEpoch 6/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7599 - accuracy: 0.3572 - val_loss: 1.7354 - val_accuracy: 0.3582\nEpoch 7/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7587 - accuracy: 0.3578 - val_loss: 1.7385 - val_accuracy: 0.3589\n\nEpoch 00007: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\nEpoch 8/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7581 - accuracy: 0.3585 - val_loss: 1.7319 - val_accuracy: 0.3601\nEpoch 9/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7587 - accuracy: 0.3594 - val_loss: 1.7322 - val_accuracy: 0.3606\nEpoch 10/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7519 - accuracy: 0.3625 - val_loss: 1.7320 - val_accuracy: 0.3613\n\nEpoch 00010: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 11/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7535 - accuracy: 0.3602 - val_loss: 1.7316 - val_accuracy: 0.3599\nEpoch 12/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7533 - accuracy: 0.3611 - val_loss: 1.7315 - val_accuracy: 0.3613\nEpoch 13/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7549 - accuracy: 0.3603 - val_loss: 1.7310 - val_accuracy: 0.3611\nEpoch 14/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7533 - accuracy: 0.3621 - val_loss: 1.7317 - val_accuracy: 0.3611\nEpoch 15/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7518 - accuracy: 0.3607 - val_loss: 1.7317 - val_accuracy: 0.3618\n\nEpoch 00015: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 16/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7548 - accuracy: 0.3602 - val_loss: 1.7307 - val_accuracy: 0.3611\nEpoch 17/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7532 - accuracy: 0.3609 - val_loss: 1.7307 - val_accuracy: 0.3610\nEpoch 18/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7526 - accuracy: 0.3618 - val_loss: 1.7305 - val_accuracy: 0.3611\nEpoch 19/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7510 - accuracy: 0.3610 - val_loss: 1.7303 - val_accuracy: 0.3602\nEpoch 20/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7534 - accuracy: 0.3587 - val_loss: 1.7305 - val_accuracy: 0.3614\nEpoch 21/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7535 - accuracy: 0.3615 - val_loss: 1.7301 - val_accuracy: 0.3615\nEpoch 22/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7547 - accuracy: 0.3606 - val_loss: 1.7303 - val_accuracy: 0.3620\nEpoch 23/100\n1500/1500 [==============================] - 8s 5ms/step - loss: 1.7531 - accuracy: 0.3587 - val_loss: 1.7299 - val_accuracy: 0.3619\nEpoch 24/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7504 - accuracy: 0.3621 - val_loss: 1.7300 - val_accuracy: 0.3615\nEpoch 25/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7537 - accuracy: 0.3606 - val_loss: 1.7301 - val_accuracy: 0.3621\n\nEpoch 00025: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\nEpoch 26/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7515 - accuracy: 0.3599 - val_loss: 1.7303 - val_accuracy: 0.3613\nEpoch 27/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7524 - accuracy: 0.3617 - val_loss: 1.7302 - val_accuracy: 0.3609\n\nEpoch 00027: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\nEpoch 28/100\n1500/1500 [==============================] - 8s 5ms/step - loss: 1.7504 - accuracy: 0.3619 - val_loss: 1.7302 - val_accuracy: 0.3604\nEpoch 29/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7481 - accuracy: 0.3629 - val_loss: 1.7302 - val_accuracy: 0.3625\n\nEpoch 00029: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\nEpoch 30/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7493 - accuracy: 0.3624 - val_loss: 1.7300 - val_accuracy: 0.3626\nEpoch 31/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7518 - accuracy: 0.3608 - val_loss: 1.7301 - val_accuracy: 0.3621\n\nEpoch 00031: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\nEpoch 32/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7495 - accuracy: 0.3604 - val_loss: 1.7301 - val_accuracy: 0.3619\nEpoch 33/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7536 - accuracy: 0.3603 - val_loss: 1.7300 - val_accuracy: 0.3619\n\nEpoch 00033: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\nEpoch 34/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7559 - accuracy: 0.3581 - val_loss: 1.7301 - val_accuracy: 0.3618\nEpoch 35/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7532 - accuracy: 0.3609 - val_loss: 1.7302 - val_accuracy: 0.3614\n\nEpoch 00035: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\nEpoch 36/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7488 - accuracy: 0.3616 - val_loss: 1.7302 - val_accuracy: 0.3616\nEpoch 37/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7518 - accuracy: 0.3630 - val_loss: 1.7301 - val_accuracy: 0.3621\n\nEpoch 00037: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\nEpoch 38/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7515 - accuracy: 0.3613 - val_loss: 1.7302 - val_accuracy: 0.3619\n[[0.01769671 0.11571796 0.04536131 ... 0.00603998 0.01249749 0.03478164]\n [0.0121957  0.01770774 0.014256   ... 0.02462397 0.0869861  0.0363039 ]\n [0.00511578 0.00708286 0.00475143 ... 0.00651554 0.02942892 0.01167066]\n ...\n [0.01608114 0.06459843 0.03552107 ... 0.01454641 0.0373112  0.04500981]\n [0.00983504 0.00693103 0.00605529 ... 0.02315484 0.10683413 0.02469089]\n [0.01298437 0.02626361 0.0201029  ... 0.02283146 0.06999042 0.04050485]]\nLogloss: 1.72991\nEpoch 1/100\n1500/1500 [==============================] - 9s 5ms/step - loss: 2.3282 - accuracy: 0.2138 - val_loss: 1.7817 - val_accuracy: 0.3675\nEpoch 2/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.8459 - accuracy: 0.3354 - val_loss: 1.7390 - val_accuracy: 0.3700\nEpoch 3/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7900 - accuracy: 0.3470 - val_loss: 1.7361 - val_accuracy: 0.3694\nEpoch 4/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7763 - accuracy: 0.3521 - val_loss: 1.7359 - val_accuracy: 0.3741\nEpoch 5/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7694 - accuracy: 0.3571 - val_loss: 1.7347 - val_accuracy: 0.3709\nEpoch 6/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7606 - accuracy: 0.3585 - val_loss: 1.7404 - val_accuracy: 0.3669\nEpoch 7/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7584 - accuracy: 0.3601 - val_loss: 1.7342 - val_accuracy: 0.3722\nEpoch 8/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7605 - accuracy: 0.3575 - val_loss: 1.7322 - val_accuracy: 0.3717\nEpoch 9/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7575 - accuracy: 0.3589 - val_loss: 1.7317 - val_accuracy: 0.3719\nEpoch 10/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7517 - accuracy: 0.3619 - val_loss: 1.7309 - val_accuracy: 0.3740\nEpoch 11/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7528 - accuracy: 0.3596 - val_loss: 1.7323 - val_accuracy: 0.3722\nEpoch 12/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7536 - accuracy: 0.3625 - val_loss: 1.7313 - val_accuracy: 0.3717\n\nEpoch 00012: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\nEpoch 13/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7542 - accuracy: 0.3604 - val_loss: 1.7305 - val_accuracy: 0.3734\nEpoch 14/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7523 - accuracy: 0.3616 - val_loss: 1.7315 - val_accuracy: 0.3731\nEpoch 15/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7499 - accuracy: 0.3613 - val_loss: 1.7326 - val_accuracy: 0.3704\n\nEpoch 00015: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 16/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7519 - accuracy: 0.3604 - val_loss: 1.7306 - val_accuracy: 0.3730\nEpoch 17/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7498 - accuracy: 0.3623 - val_loss: 1.7308 - val_accuracy: 0.3716\n\nEpoch 00017: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 18/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7483 - accuracy: 0.3625 - val_loss: 1.7311 - val_accuracy: 0.3716\nEpoch 19/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7476 - accuracy: 0.3626 - val_loss: 1.7307 - val_accuracy: 0.3719\n\nEpoch 00019: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\nEpoch 20/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7491 - accuracy: 0.3593 - val_loss: 1.7310 - val_accuracy: 0.3710\nEpoch 21/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7505 - accuracy: 0.3626 - val_loss: 1.7308 - val_accuracy: 0.3709\n\nEpoch 00021: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\nEpoch 22/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7515 - accuracy: 0.3619 - val_loss: 1.7310 - val_accuracy: 0.3713\nEpoch 23/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7512 - accuracy: 0.3616 - val_loss: 1.7308 - val_accuracy: 0.3711\n\nEpoch 00023: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\nEpoch 24/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7477 - accuracy: 0.3620 - val_loss: 1.7308 - val_accuracy: 0.3714\nEpoch 25/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7523 - accuracy: 0.3609 - val_loss: 1.7308 - val_accuracy: 0.3713\n\nEpoch 00025: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\nEpoch 26/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7491 - accuracy: 0.3599 - val_loss: 1.7310 - val_accuracy: 0.3711\nEpoch 27/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7508 - accuracy: 0.3623 - val_loss: 1.7310 - val_accuracy: 0.3713\n\nEpoch 00027: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\nEpoch 28/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7480 - accuracy: 0.3632 - val_loss: 1.7308 - val_accuracy: 0.3715\n[[0.0202765  0.132513   0.05172524 ... 0.00686946 0.01418735 0.03968042]\n [0.01395994 0.02040768 0.01636745 ... 0.02827269 0.09929139 0.0416007 ]\n [0.00576836 0.00787901 0.00528265 ... 0.00720673 0.03273087 0.01305535]\n ...\n [0.0184445  0.07441893 0.04075599 ... 0.01651461 0.04228959 0.05140268]\n [0.01126453 0.00790057 0.0068946  ... 0.02656416 0.12233645 0.02816212]\n [0.0148226  0.03002494 0.02296528 ... 0.02612712 0.07996298 0.04625322]]\nLogloss: 1.73045\nEpoch 1/100\n1500/1500 [==============================] - 8s 5ms/step - loss: 2.4027 - accuracy: 0.2086 - val_loss: 1.7921 - val_accuracy: 0.3487\nEpoch 2/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.8581 - accuracy: 0.3302 - val_loss: 1.7550 - val_accuracy: 0.3549\nEpoch 3/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7934 - accuracy: 0.3473 - val_loss: 1.7512 - val_accuracy: 0.3530\nEpoch 4/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7796 - accuracy: 0.3533 - val_loss: 1.7496 - val_accuracy: 0.3514\nEpoch 5/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7674 - accuracy: 0.3569 - val_loss: 1.7480 - val_accuracy: 0.3528\nEpoch 6/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7624 - accuracy: 0.3568 - val_loss: 1.7480 - val_accuracy: 0.3524\nEpoch 7/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7570 - accuracy: 0.3595 - val_loss: 1.7477 - val_accuracy: 0.3539\nEpoch 8/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7573 - accuracy: 0.3599 - val_loss: 1.7458 - val_accuracy: 0.3562\nEpoch 9/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7552 - accuracy: 0.3597 - val_loss: 1.7450 - val_accuracy: 0.3556\nEpoch 10/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7515 - accuracy: 0.3621 - val_loss: 1.7449 - val_accuracy: 0.3565\nEpoch 11/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7513 - accuracy: 0.3603 - val_loss: 1.7443 - val_accuracy: 0.3550\nEpoch 12/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7512 - accuracy: 0.3625 - val_loss: 1.7450 - val_accuracy: 0.3540\nEpoch 13/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7534 - accuracy: 0.3610 - val_loss: 1.7452 - val_accuracy: 0.3541\n\nEpoch 00013: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\nEpoch 14/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7495 - accuracy: 0.3620 - val_loss: 1.7454 - val_accuracy: 0.3537\nEpoch 15/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7452 - accuracy: 0.3630 - val_loss: 1.7454 - val_accuracy: 0.3544\n\nEpoch 00015: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 16/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7489 - accuracy: 0.3626 - val_loss: 1.7452 - val_accuracy: 0.3554\nEpoch 17/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7458 - accuracy: 0.3626 - val_loss: 1.7452 - val_accuracy: 0.3546\n\nEpoch 00017: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 18/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7456 - accuracy: 0.3645 - val_loss: 1.7452 - val_accuracy: 0.3543\nEpoch 19/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7437 - accuracy: 0.3634 - val_loss: 1.7450 - val_accuracy: 0.3549\n\nEpoch 00019: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\nEpoch 20/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7471 - accuracy: 0.3617 - val_loss: 1.7451 - val_accuracy: 0.3536\nEpoch 21/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7465 - accuracy: 0.3640 - val_loss: 1.7450 - val_accuracy: 0.3540\n\nEpoch 00021: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\nEpoch 22/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7480 - accuracy: 0.3638 - val_loss: 1.7451 - val_accuracy: 0.3541\nEpoch 23/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7466 - accuracy: 0.3624 - val_loss: 1.7451 - val_accuracy: 0.3543\n\nEpoch 00023: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\nEpoch 24/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7446 - accuracy: 0.3646 - val_loss: 1.7450 - val_accuracy: 0.3539\nEpoch 25/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7491 - accuracy: 0.3625 - val_loss: 1.7450 - val_accuracy: 0.3537\n\nEpoch 00025: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\nEpoch 26/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7461 - accuracy: 0.3632 - val_loss: 1.7450 - val_accuracy: 0.3537\n[[0.02282366 0.1503021  0.05806823 ... 0.00772372 0.0159691  0.0444611 ]\n [0.01564254 0.02270709 0.01829583 ... 0.03162541 0.11252132 0.04658497]\n [0.0065913  0.00881161 0.00590432 ... 0.00822445 0.03727149 0.01476527]\n ...\n [0.02071036 0.0840288  0.04577806 ... 0.01853744 0.04760562 0.05779359]\n [0.01269861 0.00902686 0.00787583 ... 0.02977412 0.13728948 0.03184169]\n [0.01668475 0.03381402 0.02588618 ... 0.02949364 0.09040028 0.05212356]]\nLogloss: 1.74429\nEpoch 1/100\n1500/1500 [==============================] - 9s 5ms/step - loss: 2.3323 - accuracy: 0.2193 - val_loss: 1.8008 - val_accuracy: 0.3602\nEpoch 2/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.8456 - accuracy: 0.3357 - val_loss: 1.7558 - val_accuracy: 0.3609\nEpoch 3/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7907 - accuracy: 0.3478 - val_loss: 1.7506 - val_accuracy: 0.3616\nEpoch 4/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7764 - accuracy: 0.3522 - val_loss: 1.7544 - val_accuracy: 0.3624\nEpoch 5/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7640 - accuracy: 0.3593 - val_loss: 1.7469 - val_accuracy: 0.3630\nEpoch 6/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7596 - accuracy: 0.3592 - val_loss: 1.7461 - val_accuracy: 0.3631\nEpoch 7/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7564 - accuracy: 0.3599 - val_loss: 1.7432 - val_accuracy: 0.3631\nEpoch 8/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7572 - accuracy: 0.3588 - val_loss: 1.7442 - val_accuracy: 0.3631\nEpoch 9/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7562 - accuracy: 0.3596 - val_loss: 1.7439 - val_accuracy: 0.3644\n\nEpoch 00009: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\nEpoch 10/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7510 - accuracy: 0.3614 - val_loss: 1.7443 - val_accuracy: 0.3650\nEpoch 11/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7517 - accuracy: 0.3614 - val_loss: 1.7431 - val_accuracy: 0.3652\nEpoch 12/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7509 - accuracy: 0.3634 - val_loss: 1.7427 - val_accuracy: 0.3638\nEpoch 13/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7536 - accuracy: 0.3616 - val_loss: 1.7433 - val_accuracy: 0.3659\nEpoch 14/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7508 - accuracy: 0.3623 - val_loss: 1.7427 - val_accuracy: 0.3650\n\nEpoch 00014: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 15/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7465 - accuracy: 0.3620 - val_loss: 1.7431 - val_accuracy: 0.3643\nEpoch 16/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7519 - accuracy: 0.3615 - val_loss: 1.7428 - val_accuracy: 0.3663\n\nEpoch 00016: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 17/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7481 - accuracy: 0.3624 - val_loss: 1.7428 - val_accuracy: 0.3655\nEpoch 18/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7480 - accuracy: 0.3637 - val_loss: 1.7430 - val_accuracy: 0.3656\n\nEpoch 00018: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\nEpoch 19/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7472 - accuracy: 0.3622 - val_loss: 1.7428 - val_accuracy: 0.3652\nEpoch 20/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7486 - accuracy: 0.3600 - val_loss: 1.7428 - val_accuracy: 0.3649\n\nEpoch 00020: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\nEpoch 21/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7491 - accuracy: 0.3635 - val_loss: 1.7427 - val_accuracy: 0.3652\nEpoch 22/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7513 - accuracy: 0.3616 - val_loss: 1.7427 - val_accuracy: 0.3658\n\nEpoch 00022: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\nEpoch 23/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7488 - accuracy: 0.3627 - val_loss: 1.7427 - val_accuracy: 0.3650\nEpoch 24/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7485 - accuracy: 0.3631 - val_loss: 1.7427 - val_accuracy: 0.3654\n\nEpoch 00024: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\nEpoch 25/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7517 - accuracy: 0.3619 - val_loss: 1.7428 - val_accuracy: 0.3649\nEpoch 26/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7479 - accuracy: 0.3624 - val_loss: 1.7428 - val_accuracy: 0.3649\n\nEpoch 00026: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\nEpoch 27/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7514 - accuracy: 0.3635 - val_loss: 1.7428 - val_accuracy: 0.3646\nEpoch 28/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7477 - accuracy: 0.3630 - val_loss: 1.7428 - val_accuracy: 0.3647\n\nEpoch 00028: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\nEpoch 29/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7473 - accuracy: 0.3642 - val_loss: 1.7426 - val_accuracy: 0.3652\nEpoch 30/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7466 - accuracy: 0.3643 - val_loss: 1.7426 - val_accuracy: 0.3658\n\nEpoch 00030: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\nEpoch 31/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7492 - accuracy: 0.3617 - val_loss: 1.7427 - val_accuracy: 0.3652\nEpoch 32/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7474 - accuracy: 0.3608 - val_loss: 1.7427 - val_accuracy: 0.3647\n\nEpoch 00032: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\nEpoch 33/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7515 - accuracy: 0.3611 - val_loss: 1.7427 - val_accuracy: 0.3650\nEpoch 34/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7516 - accuracy: 0.3600 - val_loss: 1.7427 - val_accuracy: 0.3649\n\nEpoch 00034: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\nEpoch 35/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7492 - accuracy: 0.3616 - val_loss: 1.7427 - val_accuracy: 0.3647\nEpoch 36/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7468 - accuracy: 0.3627 - val_loss: 1.7428 - val_accuracy: 0.3652\n\nEpoch 00036: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\nEpoch 37/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7477 - accuracy: 0.3628 - val_loss: 1.7427 - val_accuracy: 0.3649\nEpoch 38/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7517 - accuracy: 0.3606 - val_loss: 1.7428 - val_accuracy: 0.3651\n\nEpoch 00038: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\nEpoch 39/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7451 - accuracy: 0.3635 - val_loss: 1.7426 - val_accuracy: 0.3652\nEpoch 40/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7450 - accuracy: 0.3639 - val_loss: 1.7427 - val_accuracy: 0.3655\n\nEpoch 00040: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\nEpoch 41/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7499 - accuracy: 0.3615 - val_loss: 1.7427 - val_accuracy: 0.3656\nEpoch 42/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7479 - accuracy: 0.3628 - val_loss: 1.7427 - val_accuracy: 0.3656\n\nEpoch 00042: ReduceLROnPlateau reducing learning rate to 3.051757735406113e-09.\nEpoch 43/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7488 - accuracy: 0.3633 - val_loss: 1.7426 - val_accuracy: 0.3649\nEpoch 44/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7506 - accuracy: 0.3634 - val_loss: 1.7428 - val_accuracy: 0.3650\n\nEpoch 00044: ReduceLROnPlateau reducing learning rate to 1.5258788677030566e-09.\nEpoch 45/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7492 - accuracy: 0.3632 - val_loss: 1.7427 - val_accuracy: 0.3647\nEpoch 46/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7488 - accuracy: 0.3629 - val_loss: 1.7428 - val_accuracy: 0.3647\n\nEpoch 00046: ReduceLROnPlateau reducing learning rate to 7.629394338515283e-10.\nEpoch 47/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7484 - accuracy: 0.3626 - val_loss: 1.7427 - val_accuracy: 0.3654\nEpoch 48/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7513 - accuracy: 0.3605 - val_loss: 1.7427 - val_accuracy: 0.3652\n\nEpoch 00048: ReduceLROnPlateau reducing learning rate to 3.8146971692576415e-10.\nEpoch 49/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7508 - accuracy: 0.3612 - val_loss: 1.7427 - val_accuracy: 0.3643\nEpoch 50/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7473 - accuracy: 0.3618 - val_loss: 1.7427 - val_accuracy: 0.3652\n\nEpoch 00050: ReduceLROnPlateau reducing learning rate to 1.9073485846288207e-10.\nEpoch 51/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7469 - accuracy: 0.3618 - val_loss: 1.7428 - val_accuracy: 0.3652\nEpoch 52/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7511 - accuracy: 0.3617 - val_loss: 1.7427 - val_accuracy: 0.3646\n\nEpoch 00052: ReduceLROnPlateau reducing learning rate to 9.536742923144104e-11.\nEpoch 53/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7501 - accuracy: 0.3621 - val_loss: 1.7428 - val_accuracy: 0.3644\nEpoch 54/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7521 - accuracy: 0.3592 - val_loss: 1.7427 - val_accuracy: 0.3643\n\nEpoch 00054: ReduceLROnPlateau reducing learning rate to 4.768371461572052e-11.\nEpoch 55/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7501 - accuracy: 0.3616 - val_loss: 1.7426 - val_accuracy: 0.3656\nEpoch 56/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7463 - accuracy: 0.3631 - val_loss: 1.7427 - val_accuracy: 0.3661\n\nEpoch 00056: ReduceLROnPlateau reducing learning rate to 2.384185730786026e-11.\nEpoch 57/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7524 - accuracy: 0.3619 - val_loss: 1.7427 - val_accuracy: 0.3651\nEpoch 58/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7492 - accuracy: 0.3626 - val_loss: 1.7426 - val_accuracy: 0.3650\n\nEpoch 00058: ReduceLROnPlateau reducing learning rate to 1.192092865393013e-11.\nEpoch 59/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7466 - accuracy: 0.3639 - val_loss: 1.7428 - val_accuracy: 0.3660\nEpoch 60/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7460 - accuracy: 0.3635 - val_loss: 1.7427 - val_accuracy: 0.3640\n\nEpoch 00060: ReduceLROnPlateau reducing learning rate to 5.960464326965065e-12.\nEpoch 61/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7508 - accuracy: 0.3619 - val_loss: 1.7427 - val_accuracy: 0.3654\nEpoch 62/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7479 - accuracy: 0.3616 - val_loss: 1.7428 - val_accuracy: 0.3650\n\nEpoch 00062: ReduceLROnPlateau reducing learning rate to 2.9802321634825324e-12.\nEpoch 63/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7502 - accuracy: 0.3635 - val_loss: 1.7426 - val_accuracy: 0.3656\nEpoch 64/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7523 - accuracy: 0.3616 - val_loss: 1.7427 - val_accuracy: 0.3645\n\nEpoch 00064: ReduceLROnPlateau reducing learning rate to 1.4901160817412662e-12.\nEpoch 65/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7465 - accuracy: 0.3644 - val_loss: 1.7427 - val_accuracy: 0.3651\nEpoch 66/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7524 - accuracy: 0.3601 - val_loss: 1.7427 - val_accuracy: 0.3649\n\nEpoch 00066: ReduceLROnPlateau reducing learning rate to 7.450580408706331e-13.\nEpoch 67/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7481 - accuracy: 0.3638 - val_loss: 1.7427 - val_accuracy: 0.3645\nEpoch 68/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7505 - accuracy: 0.3627 - val_loss: 1.7428 - val_accuracy: 0.3645\n\nEpoch 00068: ReduceLROnPlateau reducing learning rate to 3.7252902043531655e-13.\nEpoch 69/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7458 - accuracy: 0.3629 - val_loss: 1.7427 - val_accuracy: 0.3645\nEpoch 70/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7496 - accuracy: 0.3621 - val_loss: 1.7428 - val_accuracy: 0.3650\n\nEpoch 00070: ReduceLROnPlateau reducing learning rate to 1.8626451021765827e-13.\nEpoch 71/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7473 - accuracy: 0.3629 - val_loss: 1.7427 - val_accuracy: 0.3654\nEpoch 72/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7483 - accuracy: 0.3603 - val_loss: 1.7427 - val_accuracy: 0.3650\n\nEpoch 00072: ReduceLROnPlateau reducing learning rate to 9.313225510882914e-14.\nEpoch 73/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7479 - accuracy: 0.3640 - val_loss: 1.7426 - val_accuracy: 0.3650\n[[0.0253735  0.16665133 0.06447523 ... 0.00858336 0.01769985 0.04949155]\n [0.01732068 0.02510983 0.02020911 ... 0.03518995 0.12535374 0.05170932]\n [0.00740602 0.00983397 0.00663189 ... 0.00922983 0.04162579 0.0165467 ]\n ...\n [0.0229121  0.09217167 0.05053706 ... 0.02075084 0.05350905 0.06432431]\n [0.01411972 0.00992101 0.00871189 ... 0.03321681 0.15264079 0.03536669]\n [0.01853897 0.03761696 0.02879521 ... 0.03275822 0.10007156 0.05787333]]\nLogloss: 1.74263\nEpoch 1/100\n1500/1500 [==============================] - 8s 5ms/step - loss: 2.3405 - accuracy: 0.2216 - val_loss: 1.7859 - val_accuracy: 0.3549\nEpoch 2/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.8462 - accuracy: 0.3360 - val_loss: 1.7569 - val_accuracy: 0.3629\nEpoch 3/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7922 - accuracy: 0.3479 - val_loss: 1.7531 - val_accuracy: 0.3626\nEpoch 4/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7761 - accuracy: 0.3540 - val_loss: 1.7510 - val_accuracy: 0.3659\nEpoch 5/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7645 - accuracy: 0.3586 - val_loss: 1.7535 - val_accuracy: 0.3605\nEpoch 6/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7608 - accuracy: 0.3581 - val_loss: 1.7506 - val_accuracy: 0.3624\nEpoch 7/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7555 - accuracy: 0.3589 - val_loss: 1.7531 - val_accuracy: 0.3634\nEpoch 8/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7588 - accuracy: 0.3585 - val_loss: 1.7491 - val_accuracy: 0.3646\nEpoch 9/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7575 - accuracy: 0.3584 - val_loss: 1.7489 - val_accuracy: 0.3660\nEpoch 10/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7533 - accuracy: 0.3594 - val_loss: 1.7495 - val_accuracy: 0.3671\nEpoch 11/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7530 - accuracy: 0.3594 - val_loss: 1.7489 - val_accuracy: 0.3641\n\nEpoch 00011: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\nEpoch 12/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7528 - accuracy: 0.3600 - val_loss: 1.7485 - val_accuracy: 0.3650\nEpoch 13/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7540 - accuracy: 0.3611 - val_loss: 1.7484 - val_accuracy: 0.3652\nEpoch 14/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7529 - accuracy: 0.3600 - val_loss: 1.7485 - val_accuracy: 0.3638\nEpoch 15/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7490 - accuracy: 0.3623 - val_loss: 1.7490 - val_accuracy: 0.3613\n\nEpoch 00015: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 16/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7514 - accuracy: 0.3594 - val_loss: 1.7487 - val_accuracy: 0.3630\nEpoch 17/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7490 - accuracy: 0.3606 - val_loss: 1.7489 - val_accuracy: 0.3601\n\nEpoch 00017: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 18/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7507 - accuracy: 0.3613 - val_loss: 1.7487 - val_accuracy: 0.3609\nEpoch 19/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7466 - accuracy: 0.3630 - val_loss: 1.7488 - val_accuracy: 0.3621\n\nEpoch 00019: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\nEpoch 20/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7484 - accuracy: 0.3620 - val_loss: 1.7489 - val_accuracy: 0.3616\nEpoch 21/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7513 - accuracy: 0.3614 - val_loss: 1.7490 - val_accuracy: 0.3619\n\nEpoch 00021: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\nEpoch 22/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7515 - accuracy: 0.3611 - val_loss: 1.7489 - val_accuracy: 0.3623\nEpoch 23/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7487 - accuracy: 0.3610 - val_loss: 1.7488 - val_accuracy: 0.3620\n\nEpoch 00023: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\nEpoch 24/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7500 - accuracy: 0.3592 - val_loss: 1.7489 - val_accuracy: 0.3615\nEpoch 25/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7517 - accuracy: 0.3614 - val_loss: 1.7490 - val_accuracy: 0.3611\n\nEpoch 00025: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\nEpoch 26/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7488 - accuracy: 0.3614 - val_loss: 1.7489 - val_accuracy: 0.3618\nEpoch 27/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7520 - accuracy: 0.3605 - val_loss: 1.7489 - val_accuracy: 0.3619\n\nEpoch 00027: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\nEpoch 28/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7483 - accuracy: 0.3619 - val_loss: 1.7489 - val_accuracy: 0.3619\n[[0.02795254 0.18354719 0.0709871  ... 0.0094107  0.0194198  0.0543925 ]\n [0.01906673 0.02747699 0.02214336 ... 0.03877361 0.13772327 0.05674386]\n [0.00806066 0.01070394 0.00723341 ... 0.01002114 0.0455233  0.01806048]\n ...\n [0.02513527 0.10118205 0.05555556 ... 0.02292424 0.05908015 0.07101752]\n [0.01549957 0.01086342 0.00955208 ... 0.03656784 0.16820634 0.03882444]\n [0.02051821 0.04133119 0.03162905 ... 0.03627093 0.11007593 0.06360143]]\nLogloss: 1.74836\nEpoch 1/100\n1500/1500 [==============================] - 8s 5ms/step - loss: 2.3447 - accuracy: 0.2383 - val_loss: 1.7887 - val_accuracy: 0.3543\nEpoch 2/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.8434 - accuracy: 0.3352 - val_loss: 1.7603 - val_accuracy: 0.3570\nEpoch 3/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7933 - accuracy: 0.3497 - val_loss: 1.7561 - val_accuracy: 0.3604\nEpoch 4/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7775 - accuracy: 0.3528 - val_loss: 1.7538 - val_accuracy: 0.3615\nEpoch 5/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7657 - accuracy: 0.3576 - val_loss: 1.7531 - val_accuracy: 0.3621\nEpoch 6/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7608 - accuracy: 0.3592 - val_loss: 1.7516 - val_accuracy: 0.3635\nEpoch 7/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7554 - accuracy: 0.3619 - val_loss: 1.7538 - val_accuracy: 0.3607\nEpoch 8/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7577 - accuracy: 0.3591 - val_loss: 1.7498 - val_accuracy: 0.3640\nEpoch 9/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7560 - accuracy: 0.3585 - val_loss: 1.7504 - val_accuracy: 0.3630\nEpoch 10/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7526 - accuracy: 0.3614 - val_loss: 1.7501 - val_accuracy: 0.3646\n\nEpoch 00010: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\nEpoch 11/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7511 - accuracy: 0.3606 - val_loss: 1.7508 - val_accuracy: 0.3641\nEpoch 12/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7517 - accuracy: 0.3616 - val_loss: 1.7508 - val_accuracy: 0.3641\n\nEpoch 00012: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 13/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7523 - accuracy: 0.3621 - val_loss: 1.7505 - val_accuracy: 0.3641\nEpoch 14/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7515 - accuracy: 0.3609 - val_loss: 1.7502 - val_accuracy: 0.3644\n\nEpoch 00014: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 15/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7478 - accuracy: 0.3617 - val_loss: 1.7503 - val_accuracy: 0.3631\nEpoch 16/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7500 - accuracy: 0.3610 - val_loss: 1.7504 - val_accuracy: 0.3635\n\nEpoch 00016: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\nEpoch 17/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7482 - accuracy: 0.3608 - val_loss: 1.7504 - val_accuracy: 0.3650\nEpoch 18/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7491 - accuracy: 0.3630 - val_loss: 1.7504 - val_accuracy: 0.3643\n\nEpoch 00018: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\nEpoch 19/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7451 - accuracy: 0.3632 - val_loss: 1.7504 - val_accuracy: 0.3636\nEpoch 20/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7483 - accuracy: 0.3612 - val_loss: 1.7504 - val_accuracy: 0.3636\n\nEpoch 00020: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\nEpoch 21/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7488 - accuracy: 0.3632 - val_loss: 1.7504 - val_accuracy: 0.3644\nEpoch 22/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7519 - accuracy: 0.3621 - val_loss: 1.7503 - val_accuracy: 0.3636\n\nEpoch 00022: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\nEpoch 23/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7492 - accuracy: 0.3625 - val_loss: 1.7504 - val_accuracy: 0.3634\n[[0.03035522 0.20056515 0.07759154 ... 0.01017477 0.02108376 0.05908251]\n [0.02089143 0.02990654 0.02414041 ... 0.04238868 0.15013351 0.06178816]\n [0.00873536 0.01155458 0.00787256 ... 0.01094962 0.05001162 0.01949516]\n ...\n [0.02742945 0.11102836 0.0609008  ... 0.02475995 0.06381235 0.0775053 ]\n [0.01699045 0.01211597 0.01066419 ... 0.04001897 0.18246374 0.04275242]\n [0.02241661 0.04471906 0.03431154 ... 0.03954118 0.12030865 0.06922257]]\nLogloss: 1.74978\nEpoch 1/100\n1500/1500 [==============================] - 8s 5ms/step - loss: 2.3609 - accuracy: 0.2204 - val_loss: 1.7920 - val_accuracy: 0.3562\nEpoch 2/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.8509 - accuracy: 0.3355 - val_loss: 1.7581 - val_accuracy: 0.3589\nEpoch 3/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7947 - accuracy: 0.3471 - val_loss: 1.7535 - val_accuracy: 0.3613\nEpoch 4/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7769 - accuracy: 0.3546 - val_loss: 1.7518 - val_accuracy: 0.3621\nEpoch 5/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7664 - accuracy: 0.3572 - val_loss: 1.7505 - val_accuracy: 0.3623\nEpoch 6/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7592 - accuracy: 0.3599 - val_loss: 1.7503 - val_accuracy: 0.3644\nEpoch 7/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7559 - accuracy: 0.3608 - val_loss: 1.7494 - val_accuracy: 0.3629\nEpoch 8/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7583 - accuracy: 0.3590 - val_loss: 1.7493 - val_accuracy: 0.3632\nEpoch 9/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7575 - accuracy: 0.3594 - val_loss: 1.7489 - val_accuracy: 0.3640\nEpoch 10/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7508 - accuracy: 0.3621 - val_loss: 1.7489 - val_accuracy: 0.3638\nEpoch 11/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7528 - accuracy: 0.3612 - val_loss: 1.7489 - val_accuracy: 0.3632\n\nEpoch 00011: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\nEpoch 12/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7527 - accuracy: 0.3620 - val_loss: 1.7491 - val_accuracy: 0.3611\nEpoch 13/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7507 - accuracy: 0.3609 - val_loss: 1.7493 - val_accuracy: 0.3618\n\nEpoch 00013: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 14/100\n1500/1500 [==============================] - 8s 5ms/step - loss: 1.7523 - accuracy: 0.3610 - val_loss: 1.7487 - val_accuracy: 0.3619\nEpoch 15/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7484 - accuracy: 0.3613 - val_loss: 1.7491 - val_accuracy: 0.3618\nEpoch 16/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7509 - accuracy: 0.3607 - val_loss: 1.7491 - val_accuracy: 0.3613\n\nEpoch 00016: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 17/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7463 - accuracy: 0.3646 - val_loss: 1.7491 - val_accuracy: 0.3613\nEpoch 18/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7490 - accuracy: 0.3627 - val_loss: 1.7489 - val_accuracy: 0.3613\n\nEpoch 00018: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\nEpoch 19/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7452 - accuracy: 0.3639 - val_loss: 1.7490 - val_accuracy: 0.3620\nEpoch 20/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7473 - accuracy: 0.3622 - val_loss: 1.7490 - val_accuracy: 0.3614\n\nEpoch 00020: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\nEpoch 21/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7478 - accuracy: 0.3624 - val_loss: 1.7489 - val_accuracy: 0.3610\nEpoch 22/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7517 - accuracy: 0.3614 - val_loss: 1.7490 - val_accuracy: 0.3613\n\nEpoch 00022: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\nEpoch 23/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7482 - accuracy: 0.3635 - val_loss: 1.7491 - val_accuracy: 0.3611\nEpoch 24/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7468 - accuracy: 0.3634 - val_loss: 1.7491 - val_accuracy: 0.3614\n\nEpoch 00024: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\nEpoch 25/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7509 - accuracy: 0.3616 - val_loss: 1.7491 - val_accuracy: 0.3602\nEpoch 26/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7467 - accuracy: 0.3616 - val_loss: 1.7491 - val_accuracy: 0.3611\n\nEpoch 00026: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\nEpoch 27/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7503 - accuracy: 0.3629 - val_loss: 1.7491 - val_accuracy: 0.3610\nEpoch 28/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7472 - accuracy: 0.3622 - val_loss: 1.7491 - val_accuracy: 0.3610\n\nEpoch 00028: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\nEpoch 29/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7477 - accuracy: 0.3630 - val_loss: 1.7491 - val_accuracy: 0.3601\n[[0.03300305 0.21719461 0.08415953 ... 0.01105572 0.02287719 0.0641926 ]\n [0.02262878 0.03211452 0.02595515 ... 0.04595601 0.16331642 0.06676017]\n [0.00946713 0.01271059 0.00862028 ... 0.0118632  0.05410686 0.02125965]\n ...\n [0.02967249 0.12029793 0.06596908 ... 0.02683775 0.06898805 0.08408405]\n [0.01842736 0.0131323  0.01157197 ... 0.04325756 0.19722326 0.04630156]\n [0.0243277  0.04859742 0.03725334 ... 0.04287628 0.12994502 0.07498024]]\nLogloss: 1.74875\nEpoch 1/100\n1500/1500 [==============================] - 8s 5ms/step - loss: 2.3613 - accuracy: 0.2105 - val_loss: 1.7822 - val_accuracy: 0.3658\nEpoch 2/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.8492 - accuracy: 0.3341 - val_loss: 1.7472 - val_accuracy: 0.3714\nEpoch 3/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7931 - accuracy: 0.3463 - val_loss: 1.7427 - val_accuracy: 0.3695\nEpoch 4/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7755 - accuracy: 0.3548 - val_loss: 1.7415 - val_accuracy: 0.3701\nEpoch 5/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7648 - accuracy: 0.3568 - val_loss: 1.7409 - val_accuracy: 0.3720\nEpoch 6/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7593 - accuracy: 0.3596 - val_loss: 1.7404 - val_accuracy: 0.3729\nEpoch 7/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7567 - accuracy: 0.3593 - val_loss: 1.7406 - val_accuracy: 0.3717\nEpoch 8/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7577 - accuracy: 0.3593 - val_loss: 1.7384 - val_accuracy: 0.3713\nEpoch 9/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7575 - accuracy: 0.3579 - val_loss: 1.7381 - val_accuracy: 0.3713\nEpoch 10/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7513 - accuracy: 0.3614 - val_loss: 1.7383 - val_accuracy: 0.3724\nEpoch 11/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7532 - accuracy: 0.3608 - val_loss: 1.7383 - val_accuracy: 0.3706\n\nEpoch 00011: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\nEpoch 12/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7499 - accuracy: 0.3619 - val_loss: 1.7391 - val_accuracy: 0.3706\nEpoch 13/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7507 - accuracy: 0.3612 - val_loss: 1.7382 - val_accuracy: 0.3704\n\nEpoch 00013: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 14/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7519 - accuracy: 0.3602 - val_loss: 1.7385 - val_accuracy: 0.3719\nEpoch 15/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7487 - accuracy: 0.3623 - val_loss: 1.7385 - val_accuracy: 0.3695\n\nEpoch 00015: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 16/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7499 - accuracy: 0.3605 - val_loss: 1.7382 - val_accuracy: 0.3700\nEpoch 17/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7443 - accuracy: 0.3634 - val_loss: 1.7384 - val_accuracy: 0.3690\n\nEpoch 00017: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\nEpoch 18/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7480 - accuracy: 0.3633 - val_loss: 1.7384 - val_accuracy: 0.3690\nEpoch 19/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7440 - accuracy: 0.3638 - val_loss: 1.7383 - val_accuracy: 0.3691\n\nEpoch 00019: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\nEpoch 20/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7454 - accuracy: 0.3612 - val_loss: 1.7384 - val_accuracy: 0.3700\nEpoch 21/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7481 - accuracy: 0.3625 - val_loss: 1.7385 - val_accuracy: 0.3700\n\nEpoch 00021: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\nEpoch 22/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7511 - accuracy: 0.3620 - val_loss: 1.7383 - val_accuracy: 0.3700\nEpoch 23/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7465 - accuracy: 0.3625 - val_loss: 1.7382 - val_accuracy: 0.3700\n\nEpoch 00023: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\nEpoch 24/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7456 - accuracy: 0.3642 - val_loss: 1.7384 - val_accuracy: 0.3699\n[[0.03554144 0.23425808 0.09069456 ... 0.01185365 0.02442477 0.06889782]\n [0.02439115 0.03425527 0.02781511 ... 0.04941877 0.17615168 0.07157791]\n [0.01020319 0.01360388 0.00923694 ... 0.01286937 0.05872709 0.02297586]\n ...\n [0.0320531  0.13016527 0.0712132  ... 0.02876438 0.07371634 0.09039049]\n [0.02000031 0.01414042 0.01254239 ... 0.04672369 0.21239496 0.04992006]\n [0.02615369 0.05159344 0.03966089 ... 0.04630755 0.14090143 0.08037827]]\nLogloss: 1.73810\nEpoch 1/100\n1500/1500 [==============================] - 9s 5ms/step - loss: 2.3547 - accuracy: 0.2120 - val_loss: 1.7927 - val_accuracy: 0.3551\nEpoch 2/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.8465 - accuracy: 0.3351 - val_loss: 1.7504 - val_accuracy: 0.3559\nEpoch 3/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7943 - accuracy: 0.3463 - val_loss: 1.7431 - val_accuracy: 0.3604\nEpoch 4/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7759 - accuracy: 0.3549 - val_loss: 1.7408 - val_accuracy: 0.3636\nEpoch 5/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7656 - accuracy: 0.3581 - val_loss: 1.7400 - val_accuracy: 0.3664\nEpoch 6/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7610 - accuracy: 0.3615 - val_loss: 1.7406 - val_accuracy: 0.3631\nEpoch 7/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7588 - accuracy: 0.3595 - val_loss: 1.7383 - val_accuracy: 0.3661\nEpoch 8/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7600 - accuracy: 0.3588 - val_loss: 1.7384 - val_accuracy: 0.3650\nEpoch 9/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7583 - accuracy: 0.3585 - val_loss: 1.7367 - val_accuracy: 0.3650\nEpoch 10/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7527 - accuracy: 0.3620 - val_loss: 1.7363 - val_accuracy: 0.3658\nEpoch 11/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7547 - accuracy: 0.3609 - val_loss: 1.7358 - val_accuracy: 0.3684\nEpoch 12/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7538 - accuracy: 0.3617 - val_loss: 1.7353 - val_accuracy: 0.3691\nEpoch 13/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7523 - accuracy: 0.3601 - val_loss: 1.7361 - val_accuracy: 0.3677\nEpoch 14/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7544 - accuracy: 0.3612 - val_loss: 1.7380 - val_accuracy: 0.3659\n\nEpoch 00014: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\nEpoch 15/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7498 - accuracy: 0.3616 - val_loss: 1.7370 - val_accuracy: 0.3668\nEpoch 16/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7508 - accuracy: 0.3607 - val_loss: 1.7364 - val_accuracy: 0.3658\n\nEpoch 00016: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 17/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7463 - accuracy: 0.3623 - val_loss: 1.7365 - val_accuracy: 0.3684\nEpoch 18/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7500 - accuracy: 0.3623 - val_loss: 1.7362 - val_accuracy: 0.3677\n\nEpoch 00018: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 19/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7447 - accuracy: 0.3639 - val_loss: 1.7361 - val_accuracy: 0.3666\nEpoch 20/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7462 - accuracy: 0.3616 - val_loss: 1.7357 - val_accuracy: 0.3672\n\nEpoch 00020: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\nEpoch 21/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7491 - accuracy: 0.3628 - val_loss: 1.7360 - val_accuracy: 0.3670\nEpoch 22/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7505 - accuracy: 0.3636 - val_loss: 1.7363 - val_accuracy: 0.3671\n\nEpoch 00022: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\nEpoch 23/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7481 - accuracy: 0.3624 - val_loss: 1.7360 - val_accuracy: 0.3670\nEpoch 24/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7455 - accuracy: 0.3641 - val_loss: 1.7361 - val_accuracy: 0.3674\n\nEpoch 00024: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\nEpoch 25/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7493 - accuracy: 0.3624 - val_loss: 1.7361 - val_accuracy: 0.3675\nEpoch 26/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7458 - accuracy: 0.3621 - val_loss: 1.7361 - val_accuracy: 0.3674\n\nEpoch 00026: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\nEpoch 27/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7499 - accuracy: 0.3638 - val_loss: 1.7362 - val_accuracy: 0.3670\n[[0.03790691 0.25075857 0.09726697 ... 0.01276948 0.02616225 0.07410241]\n [0.02610165 0.03669817 0.02976559 ... 0.05287639 0.1890626  0.07653306]\n [0.0110061  0.01446153 0.00986929 ... 0.01372537 0.06270117 0.02448668]\n ...\n [0.03424639 0.13893247 0.07601936 ... 0.03102183 0.07948973 0.09684704]\n [0.02135933 0.01498464 0.01331231 ... 0.04995378 0.22794282 0.05304266]\n [0.02806626 0.05494618 0.04233252 ... 0.04988252 0.15174547 0.08598153]]\nLogloss: 1.73532\nEpoch 1/100\n1500/1500 [==============================] - 9s 5ms/step - loss: 2.3477 - accuracy: 0.2149 - val_loss: 1.8054 - val_accuracy: 0.3500\nEpoch 2/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.8447 - accuracy: 0.3385 - val_loss: 1.7534 - val_accuracy: 0.3576\nEpoch 3/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7925 - accuracy: 0.3469 - val_loss: 1.7479 - val_accuracy: 0.3614\nEpoch 4/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7747 - accuracy: 0.3539 - val_loss: 1.7445 - val_accuracy: 0.3668\nEpoch 5/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7644 - accuracy: 0.3588 - val_loss: 1.7427 - val_accuracy: 0.3658\nEpoch 6/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7599 - accuracy: 0.3606 - val_loss: 1.7428 - val_accuracy: 0.3677\nEpoch 7/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7562 - accuracy: 0.3596 - val_loss: 1.7430 - val_accuracy: 0.3649\n\nEpoch 00007: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\nEpoch 8/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7588 - accuracy: 0.3586 - val_loss: 1.7419 - val_accuracy: 0.3645\nEpoch 9/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7573 - accuracy: 0.3596 - val_loss: 1.7422 - val_accuracy: 0.3647\nEpoch 10/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7536 - accuracy: 0.3612 - val_loss: 1.7419 - val_accuracy: 0.3636\n\nEpoch 00010: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 11/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7550 - accuracy: 0.3595 - val_loss: 1.7416 - val_accuracy: 0.3625\nEpoch 12/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7538 - accuracy: 0.3612 - val_loss: 1.7416 - val_accuracy: 0.3620\nEpoch 13/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7534 - accuracy: 0.3604 - val_loss: 1.7413 - val_accuracy: 0.3650\nEpoch 14/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7561 - accuracy: 0.3614 - val_loss: 1.7413 - val_accuracy: 0.3640\nEpoch 15/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7524 - accuracy: 0.3611 - val_loss: 1.7414 - val_accuracy: 0.3623\n\nEpoch 00015: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 16/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7523 - accuracy: 0.3614 - val_loss: 1.7412 - val_accuracy: 0.3643\nEpoch 17/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7485 - accuracy: 0.3624 - val_loss: 1.7412 - val_accuracy: 0.3618\n\nEpoch 00017: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\nEpoch 18/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7518 - accuracy: 0.3630 - val_loss: 1.7412 - val_accuracy: 0.3626\nEpoch 19/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7491 - accuracy: 0.3624 - val_loss: 1.7411 - val_accuracy: 0.3634\nEpoch 20/100\n1500/1500 [==============================] - 8s 5ms/step - loss: 1.7505 - accuracy: 0.3599 - val_loss: 1.7411 - val_accuracy: 0.3623\nEpoch 21/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7531 - accuracy: 0.3607 - val_loss: 1.7409 - val_accuracy: 0.3623\nEpoch 22/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7532 - accuracy: 0.3628 - val_loss: 1.7409 - val_accuracy: 0.3627\nEpoch 23/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7513 - accuracy: 0.3605 - val_loss: 1.7408 - val_accuracy: 0.3629\nEpoch 24/100\n1500/1500 [==============================] - 8s 5ms/step - loss: 1.7502 - accuracy: 0.3622 - val_loss: 1.7410 - val_accuracy: 0.3638\nEpoch 25/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7533 - accuracy: 0.3612 - val_loss: 1.7409 - val_accuracy: 0.3630\n\nEpoch 00025: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\nEpoch 26/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7495 - accuracy: 0.3614 - val_loss: 1.7410 - val_accuracy: 0.3634\nEpoch 27/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7520 - accuracy: 0.3618 - val_loss: 1.7410 - val_accuracy: 0.3630\n\nEpoch 00027: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\nEpoch 28/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7504 - accuracy: 0.3603 - val_loss: 1.7411 - val_accuracy: 0.3632\nEpoch 29/100\n1500/1500 [==============================] - 8s 5ms/step - loss: 1.7515 - accuracy: 0.3608 - val_loss: 1.7409 - val_accuracy: 0.3630\n\nEpoch 00029: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\nEpoch 30/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7483 - accuracy: 0.3638 - val_loss: 1.7409 - val_accuracy: 0.3624\nEpoch 31/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7544 - accuracy: 0.3595 - val_loss: 1.7410 - val_accuracy: 0.3632\n\nEpoch 00031: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\nEpoch 32/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7499 - accuracy: 0.3600 - val_loss: 1.7409 - val_accuracy: 0.3632\nEpoch 33/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7522 - accuracy: 0.3599 - val_loss: 1.7409 - val_accuracy: 0.3625\n\nEpoch 00033: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\nEpoch 34/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7549 - accuracy: 0.3616 - val_loss: 1.7410 - val_accuracy: 0.3630\nEpoch 35/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7506 - accuracy: 0.3609 - val_loss: 1.7410 - val_accuracy: 0.3632\n\nEpoch 00035: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\nEpoch 36/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7499 - accuracy: 0.3617 - val_loss: 1.7410 - val_accuracy: 0.3635\nEpoch 37/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7504 - accuracy: 0.3621 - val_loss: 1.7410 - val_accuracy: 0.3625\n\nEpoch 00037: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\nEpoch 38/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7534 - accuracy: 0.3606 - val_loss: 1.7410 - val_accuracy: 0.3629\n[[0.04039986 0.26742946 0.10383383 ... 0.0136242  0.02783805 0.07898027]\n [0.02785723 0.03905471 0.03170143 ... 0.05641315 0.20185633 0.08155699]\n [0.01162582 0.01526909 0.01034791 ... 0.01450711 0.06633455 0.02591059]\n ...\n [0.03652485 0.14789138 0.08106764 ... 0.03314165 0.08485587 0.10340019]\n [0.02278608 0.01589945 0.01416546 ... 0.05335362 0.24341952 0.05654651]\n [0.02994333 0.05879809 0.0452653  ... 0.05336549 0.16184425 0.09190422]]\nLogloss: 1.74079\nEpoch 1/100\n1500/1500 [==============================] - 8s 5ms/step - loss: 2.3191 - accuracy: 0.2368 - val_loss: 1.7875 - val_accuracy: 0.3511\nEpoch 2/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.8431 - accuracy: 0.3350 - val_loss: 1.7539 - val_accuracy: 0.3523\nEpoch 3/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7946 - accuracy: 0.3479 - val_loss: 1.7487 - val_accuracy: 0.3546\nEpoch 4/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7776 - accuracy: 0.3542 - val_loss: 1.7470 - val_accuracy: 0.3561\nEpoch 5/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7648 - accuracy: 0.3601 - val_loss: 1.7463 - val_accuracy: 0.3559\nEpoch 6/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7608 - accuracy: 0.3602 - val_loss: 1.7480 - val_accuracy: 0.3556\nEpoch 7/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7567 - accuracy: 0.3592 - val_loss: 1.7462 - val_accuracy: 0.3559\n\nEpoch 00007: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\nEpoch 8/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7590 - accuracy: 0.3601 - val_loss: 1.7449 - val_accuracy: 0.3554\nEpoch 9/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7583 - accuracy: 0.3597 - val_loss: 1.7442 - val_accuracy: 0.3554\nEpoch 10/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7536 - accuracy: 0.3609 - val_loss: 1.7443 - val_accuracy: 0.3548\nEpoch 11/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7551 - accuracy: 0.3594 - val_loss: 1.7447 - val_accuracy: 0.3556\n\nEpoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 12/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7532 - accuracy: 0.3608 - val_loss: 1.7451 - val_accuracy: 0.3550\nEpoch 13/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7538 - accuracy: 0.3601 - val_loss: 1.7445 - val_accuracy: 0.3550\n\nEpoch 00013: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 14/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7572 - accuracy: 0.3594 - val_loss: 1.7448 - val_accuracy: 0.3549\nEpoch 15/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7524 - accuracy: 0.3602 - val_loss: 1.7451 - val_accuracy: 0.3540\n\nEpoch 00015: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\nEpoch 16/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7523 - accuracy: 0.3611 - val_loss: 1.7450 - val_accuracy: 0.3556\nEpoch 17/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7491 - accuracy: 0.3615 - val_loss: 1.7450 - val_accuracy: 0.3546\n\nEpoch 00017: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\nEpoch 18/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7529 - accuracy: 0.3623 - val_loss: 1.7450 - val_accuracy: 0.3550\nEpoch 19/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7504 - accuracy: 0.3629 - val_loss: 1.7449 - val_accuracy: 0.3549\n\nEpoch 00019: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\nEpoch 20/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7503 - accuracy: 0.3607 - val_loss: 1.7449 - val_accuracy: 0.3551\nEpoch 21/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7541 - accuracy: 0.3618 - val_loss: 1.7449 - val_accuracy: 0.3545\n\nEpoch 00021: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\nEpoch 22/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7534 - accuracy: 0.3601 - val_loss: 1.7448 - val_accuracy: 0.3551\nEpoch 23/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7518 - accuracy: 0.3610 - val_loss: 1.7447 - val_accuracy: 0.3551\n\nEpoch 00023: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\nEpoch 24/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7512 - accuracy: 0.3616 - val_loss: 1.7449 - val_accuracy: 0.3546\n[[0.04298878 0.28376993 0.11012241 ... 0.01453959 0.02978016 0.08417601]\n [0.02966847 0.0416168  0.03375759 ... 0.05987243 0.21409184 0.08673089]\n [0.01240757 0.01629137 0.01106963 ... 0.01552824 0.07084166 0.02766408]\n ...\n [0.03896039 0.15883158 0.0866208  ... 0.03498947 0.08942512 0.10986777]\n [0.02421513 0.01689404 0.01504185 ... 0.05659716 0.25835603 0.06007785]\n [0.03180896 0.06289316 0.04835521 ... 0.05678686 0.17142176 0.097633  ]]\nLogloss: 1.74419\nEpoch 1/100\n1500/1500 [==============================] - 8s 5ms/step - loss: 2.3365 - accuracy: 0.2236 - val_loss: 1.7916 - val_accuracy: 0.3544\nEpoch 2/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.8431 - accuracy: 0.3377 - val_loss: 1.7579 - val_accuracy: 0.3551\nEpoch 3/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7913 - accuracy: 0.3449 - val_loss: 1.7539 - val_accuracy: 0.3581\nEpoch 4/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7754 - accuracy: 0.3554 - val_loss: 1.7523 - val_accuracy: 0.3546\nEpoch 5/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7644 - accuracy: 0.3576 - val_loss: 1.7527 - val_accuracy: 0.3562\nEpoch 6/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7605 - accuracy: 0.3609 - val_loss: 1.7518 - val_accuracy: 0.3596\nEpoch 7/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7554 - accuracy: 0.3602 - val_loss: 1.7510 - val_accuracy: 0.3579\nEpoch 8/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7578 - accuracy: 0.3583 - val_loss: 1.7512 - val_accuracy: 0.3573\nEpoch 9/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7562 - accuracy: 0.3585 - val_loss: 1.7502 - val_accuracy: 0.3596\nEpoch 10/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7520 - accuracy: 0.3614 - val_loss: 1.7507 - val_accuracy: 0.3579\nEpoch 11/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7532 - accuracy: 0.3605 - val_loss: 1.7501 - val_accuracy: 0.3577\n\nEpoch 00011: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\nEpoch 12/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7498 - accuracy: 0.3634 - val_loss: 1.7500 - val_accuracy: 0.3568\nEpoch 13/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7505 - accuracy: 0.3602 - val_loss: 1.7499 - val_accuracy: 0.3580\nEpoch 14/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7541 - accuracy: 0.3609 - val_loss: 1.7502 - val_accuracy: 0.3589\n\nEpoch 00014: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 15/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7499 - accuracy: 0.3606 - val_loss: 1.7503 - val_accuracy: 0.3600\nEpoch 16/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7514 - accuracy: 0.3597 - val_loss: 1.7505 - val_accuracy: 0.3591\n\nEpoch 00016: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 17/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7452 - accuracy: 0.3637 - val_loss: 1.7504 - val_accuracy: 0.3596\nEpoch 18/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7486 - accuracy: 0.3635 - val_loss: 1.7505 - val_accuracy: 0.3590\n\nEpoch 00018: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\nEpoch 19/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7456 - accuracy: 0.3654 - val_loss: 1.7504 - val_accuracy: 0.3599\nEpoch 20/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7476 - accuracy: 0.3605 - val_loss: 1.7504 - val_accuracy: 0.3600\n\nEpoch 00020: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\nEpoch 21/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7493 - accuracy: 0.3630 - val_loss: 1.7503 - val_accuracy: 0.3596\nEpoch 22/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7505 - accuracy: 0.3630 - val_loss: 1.7504 - val_accuracy: 0.3598\n\nEpoch 00022: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\nEpoch 23/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7477 - accuracy: 0.3631 - val_loss: 1.7503 - val_accuracy: 0.3594\nEpoch 24/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7459 - accuracy: 0.3640 - val_loss: 1.7503 - val_accuracy: 0.3587\n\nEpoch 00024: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\nEpoch 25/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7472 - accuracy: 0.3635 - val_loss: 1.7504 - val_accuracy: 0.3590\nEpoch 26/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7458 - accuracy: 0.3637 - val_loss: 1.7503 - val_accuracy: 0.3596\n\nEpoch 00026: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\nEpoch 27/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7502 - accuracy: 0.3621 - val_loss: 1.7503 - val_accuracy: 0.3596\nEpoch 28/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7455 - accuracy: 0.3620 - val_loss: 1.7503 - val_accuracy: 0.3594\n\nEpoch 00028: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n[[0.04569665 0.30071376 0.11636539 ... 0.01533865 0.03155165 0.08899025]\n [0.03138436 0.04408444 0.03570216 ... 0.06344479 0.226847   0.09179452]\n [0.01307932 0.01714011 0.01159606 ... 0.01635619 0.07473648 0.02909068]\n ...\n [0.04131608 0.16788325 0.09154405 ... 0.03707905 0.0949422  0.11628508]\n [0.02567213 0.01791387 0.01591068 ... 0.05998496 0.27305689 0.06365639]\n [0.03367025 0.06679853 0.0512644  ... 0.06012792 0.18151483 0.10359989]]\nLogloss: 1.74995\nEpoch 1/100\n1500/1500 [==============================] - 8s 5ms/step - loss: 2.3596 - accuracy: 0.2232 - val_loss: 1.8279 - val_accuracy: 0.3496\nEpoch 2/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.8648 - accuracy: 0.3290 - val_loss: 1.7667 - val_accuracy: 0.3576\nEpoch 3/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7947 - accuracy: 0.3477 - val_loss: 1.7597 - val_accuracy: 0.3564\nEpoch 4/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7769 - accuracy: 0.3534 - val_loss: 1.7571 - val_accuracy: 0.3559\nEpoch 5/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7639 - accuracy: 0.3599 - val_loss: 1.7559 - val_accuracy: 0.3560\nEpoch 6/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7597 - accuracy: 0.3597 - val_loss: 1.7554 - val_accuracy: 0.3568\nEpoch 7/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7567 - accuracy: 0.3611 - val_loss: 1.7550 - val_accuracy: 0.3580\nEpoch 8/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7590 - accuracy: 0.3591 - val_loss: 1.7552 - val_accuracy: 0.3575\nEpoch 9/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7559 - accuracy: 0.3595 - val_loss: 1.7548 - val_accuracy: 0.3582\nEpoch 10/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7537 - accuracy: 0.3610 - val_loss: 1.7542 - val_accuracy: 0.3566\nEpoch 11/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7545 - accuracy: 0.3598 - val_loss: 1.7559 - val_accuracy: 0.3574\nEpoch 12/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7511 - accuracy: 0.3617 - val_loss: 1.7544 - val_accuracy: 0.3590\n\nEpoch 00012: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\nEpoch 13/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7526 - accuracy: 0.3611 - val_loss: 1.7544 - val_accuracy: 0.3569\nEpoch 14/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7553 - accuracy: 0.3582 - val_loss: 1.7543 - val_accuracy: 0.3562\n\nEpoch 00014: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 15/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7505 - accuracy: 0.3611 - val_loss: 1.7542 - val_accuracy: 0.3575\nEpoch 16/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7525 - accuracy: 0.3598 - val_loss: 1.7541 - val_accuracy: 0.3570\nEpoch 17/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7483 - accuracy: 0.3623 - val_loss: 1.7539 - val_accuracy: 0.3559\nEpoch 18/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7513 - accuracy: 0.3618 - val_loss: 1.7540 - val_accuracy: 0.3570\nEpoch 19/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7461 - accuracy: 0.3646 - val_loss: 1.7540 - val_accuracy: 0.3564\n\nEpoch 00019: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 20/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7487 - accuracy: 0.3608 - val_loss: 1.7538 - val_accuracy: 0.3562\nEpoch 21/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7507 - accuracy: 0.3620 - val_loss: 1.7540 - val_accuracy: 0.3570\nEpoch 22/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7520 - accuracy: 0.3608 - val_loss: 1.7541 - val_accuracy: 0.3559\n\nEpoch 00022: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\nEpoch 23/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7492 - accuracy: 0.3638 - val_loss: 1.7541 - val_accuracy: 0.3554\nEpoch 24/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7471 - accuracy: 0.3624 - val_loss: 1.7541 - val_accuracy: 0.3564\n\nEpoch 00024: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\nEpoch 25/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7498 - accuracy: 0.3622 - val_loss: 1.7541 - val_accuracy: 0.3561\nEpoch 26/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7461 - accuracy: 0.3629 - val_loss: 1.7541 - val_accuracy: 0.3551\n\nEpoch 00026: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\nEpoch 27/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7507 - accuracy: 0.3628 - val_loss: 1.7541 - val_accuracy: 0.3557\nEpoch 28/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7463 - accuracy: 0.3626 - val_loss: 1.7541 - val_accuracy: 0.3565\n\nEpoch 00028: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\nEpoch 29/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7506 - accuracy: 0.3609 - val_loss: 1.7541 - val_accuracy: 0.3557\nEpoch 30/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7460 - accuracy: 0.3632 - val_loss: 1.7541 - val_accuracy: 0.3560\n\nEpoch 00030: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\nEpoch 31/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7523 - accuracy: 0.3616 - val_loss: 1.7541 - val_accuracy: 0.3564\nEpoch 32/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7479 - accuracy: 0.3610 - val_loss: 1.7541 - val_accuracy: 0.3557\n\nEpoch 00032: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\nEpoch 33/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7487 - accuracy: 0.3612 - val_loss: 1.7542 - val_accuracy: 0.3555\nEpoch 34/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7499 - accuracy: 0.3604 - val_loss: 1.7541 - val_accuracy: 0.3557\n\nEpoch 00034: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\nEpoch 35/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7458 - accuracy: 0.3625 - val_loss: 1.7541 - val_accuracy: 0.3556\n[[0.04831873 0.31641196 0.12267385 ... 0.01627815 0.03353996 0.09423893]\n [0.03319957 0.04662342 0.03770942 ... 0.0670061  0.23950501 0.09707369]\n [0.01385257 0.01810547 0.0122458  ... 0.01728415 0.07880082 0.03071537]\n ...\n [0.04352529 0.17662149 0.0964872  ... 0.03925852 0.10045905 0.12277238]\n [0.02710005 0.01883986 0.01673549 ... 0.06313192 0.28833276 0.06707169]\n [0.03567088 0.07043446 0.05409001 ... 0.06366392 0.19179356 0.10948726]]\nLogloss: 1.75379\nEpoch 1/100\n1500/1500 [==============================] - 9s 5ms/step - loss: 2.3107 - accuracy: 0.2303 - val_loss: 1.8017 - val_accuracy: 0.3506\nEpoch 2/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.8442 - accuracy: 0.3376 - val_loss: 1.7579 - val_accuracy: 0.3569\nEpoch 3/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7916 - accuracy: 0.3470 - val_loss: 1.7547 - val_accuracy: 0.3564\nEpoch 4/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7726 - accuracy: 0.3571 - val_loss: 1.7520 - val_accuracy: 0.3545\nEpoch 5/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7640 - accuracy: 0.3587 - val_loss: 1.7502 - val_accuracy: 0.3582\nEpoch 6/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7602 - accuracy: 0.3602 - val_loss: 1.7501 - val_accuracy: 0.3556\nEpoch 7/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7541 - accuracy: 0.3627 - val_loss: 1.7493 - val_accuracy: 0.3573\nEpoch 8/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7574 - accuracy: 0.3605 - val_loss: 1.7487 - val_accuracy: 0.3549\nEpoch 9/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7554 - accuracy: 0.3604 - val_loss: 1.7487 - val_accuracy: 0.3532\nEpoch 10/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7501 - accuracy: 0.3631 - val_loss: 1.7493 - val_accuracy: 0.3559\n\nEpoch 00010: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\nEpoch 11/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7526 - accuracy: 0.3593 - val_loss: 1.7488 - val_accuracy: 0.3565\nEpoch 12/100\n1095/1500 [====================>.........] - ETA: 1s - loss: 1.7469 - accuracy: 0.3645","output_type":"stream"},{"text":"IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n","name":"stderr","output_type":"stream"},{"name":"stdout","text":"1500/1500 [==============================] - 7s 5ms/step - loss: 1.7447 - accuracy: 0.3636 - val_loss: 1.7497 - val_accuracy: 0.3577\n\nEpoch 00024: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\nEpoch 25/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7453 - accuracy: 0.3641 - val_loss: 1.7497 - val_accuracy: 0.3573\nEpoch 26/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7445 - accuracy: 0.3641 - val_loss: 1.7497 - val_accuracy: 0.3571\n\nEpoch 00026: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\nEpoch 27/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7470 - accuracy: 0.3642 - val_loss: 1.7497 - val_accuracy: 0.3570\n[[0.05094859 0.33190156 0.12920744 ... 0.01724987 0.03553454 0.0994939 ]\n [0.03499963 0.04901632 0.03973689 ... 0.07070757 0.25191822 0.10214995]\n [0.0146192  0.01911846 0.01289388 ... 0.0182364  0.08276553 0.03240843]\n ...\n [0.04562539 0.18502459 0.10126004 ... 0.04150841 0.10631135 0.12946927]\n [0.0285009  0.01988227 0.01766174 ... 0.0663825  0.30285768 0.07065069]\n [0.03775422 0.07418773 0.05701656 ... 0.06714404 0.20133145 0.11532105]]\nLogloss: 1.74852\nEpoch 1/100\n1500/1500 [==============================] - 8s 5ms/step - loss: 2.3467 - accuracy: 0.2172 - val_loss: 1.7819 - val_accuracy: 0.3626\nEpoch 2/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.8504 - accuracy: 0.3354 - val_loss: 1.7465 - val_accuracy: 0.3641\nEpoch 3/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7948 - accuracy: 0.3485 - val_loss: 1.7424 - val_accuracy: 0.3632\nEpoch 4/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7780 - accuracy: 0.3542 - val_loss: 1.7407 - val_accuracy: 0.3629\nEpoch 5/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7694 - accuracy: 0.3574 - val_loss: 1.7393 - val_accuracy: 0.3613\nEpoch 6/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7630 - accuracy: 0.3580 - val_loss: 1.7407 - val_accuracy: 0.3632\nEpoch 7/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7583 - accuracy: 0.3589 - val_loss: 1.7387 - val_accuracy: 0.3658\nEpoch 8/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7600 - accuracy: 0.3592 - val_loss: 1.7372 - val_accuracy: 0.3655\nEpoch 9/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7569 - accuracy: 0.3594 - val_loss: 1.7364 - val_accuracy: 0.3614\nEpoch 10/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7536 - accuracy: 0.3609 - val_loss: 1.7365 - val_accuracy: 0.3629\nEpoch 11/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7557 - accuracy: 0.3587 - val_loss: 1.7357 - val_accuracy: 0.3663\nEpoch 12/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7523 - accuracy: 0.3616 - val_loss: 1.7356 - val_accuracy: 0.3638\nEpoch 13/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7528 - accuracy: 0.3597 - val_loss: 1.7351 - val_accuracy: 0.3627\nEpoch 14/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7568 - accuracy: 0.3580 - val_loss: 1.7352 - val_accuracy: 0.3635\nEpoch 15/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7529 - accuracy: 0.3605 - val_loss: 1.7359 - val_accuracy: 0.3618\n\nEpoch 00015: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\nEpoch 16/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7512 - accuracy: 0.3611 - val_loss: 1.7355 - val_accuracy: 0.3616\nEpoch 17/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7469 - accuracy: 0.3619 - val_loss: 1.7357 - val_accuracy: 0.3621\n\nEpoch 00017: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 18/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7490 - accuracy: 0.3625 - val_loss: 1.7357 - val_accuracy: 0.3618\nEpoch 19/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7458 - accuracy: 0.3638 - val_loss: 1.7352 - val_accuracy: 0.3613\n\nEpoch 00019: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 20/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7459 - accuracy: 0.3630 - val_loss: 1.7354 - val_accuracy: 0.3624\nEpoch 21/100\n 891/1500 [================>.............] - ETA: 2s - loss: 1.7488 - accuracy: 0.3615","output_type":"stream"},{"text":"IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n","name":"stderr","output_type":"stream"},{"name":"stdout","text":"1500/1500 [==============================] - 7s 4ms/step - loss: 1.7432 - accuracy: 0.3640 - val_loss: 1.7353 - val_accuracy: 0.3641\nEpoch 31/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7506 - accuracy: 0.3622 - val_loss: 1.7353 - val_accuracy: 0.3643\n\nEpoch 00031: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\nEpoch 32/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7448 - accuracy: 0.3638 - val_loss: 1.7354 - val_accuracy: 0.3649\nEpoch 33/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7479 - accuracy: 0.3627 - val_loss: 1.7353 - val_accuracy: 0.3640\n\nEpoch 00033: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\nEpoch 34/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7488 - accuracy: 0.3617 - val_loss: 1.7355 - val_accuracy: 0.3647\nEpoch 35/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7464 - accuracy: 0.3601 - val_loss: 1.7354 - val_accuracy: 0.3638\n\nEpoch 00035: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\nEpoch 36/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7434 - accuracy: 0.3644 - val_loss: 1.7355 - val_accuracy: 0.3638\nEpoch 37/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7470 - accuracy: 0.3630 - val_loss: 1.7354 - val_accuracy: 0.3644\n\nEpoch 00037: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\nEpoch 38/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7482 - accuracy: 0.3622 - val_loss: 1.7353 - val_accuracy: 0.3645\n[[0.05360083 0.34843568 0.13564003 ... 0.01810878 0.03724113 0.10454725]\n [0.03677339 0.05169566 0.04190828 ... 0.07424545 0.26387083 0.10749445]\n [0.0153486  0.01998638 0.01352803 ... 0.01919495 0.0869404  0.03404152]\n ...\n [0.04778858 0.19373975 0.1061262  ... 0.04369452 0.11208188 0.13606995]\n [0.02993013 0.02081011 0.01851116 ... 0.06980071 0.31839464 0.07415107]\n [0.03975738 0.07794366 0.06006039 ... 0.07062968 0.21073027 0.1212113 ]]\nLogloss: 1.73490\nEpoch 1/100\n1500/1500 [==============================] - 8s 5ms/step - loss: 2.3714 - accuracy: 0.2115 - val_loss: 1.8060 - val_accuracy: 0.3539\nEpoch 2/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.8487 - accuracy: 0.3331 - val_loss: 1.7575 - val_accuracy: 0.3565\nEpoch 3/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7936 - accuracy: 0.3467 - val_loss: 1.7529 - val_accuracy: 0.3564\nEpoch 4/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7755 - accuracy: 0.3549 - val_loss: 1.7496 - val_accuracy: 0.3561\nEpoch 5/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7669 - accuracy: 0.3575 - val_loss: 1.7484 - val_accuracy: 0.3585\nEpoch 6/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7610 - accuracy: 0.3586 - val_loss: 1.7478 - val_accuracy: 0.3591\nEpoch 7/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7573 - accuracy: 0.3605 - val_loss: 1.7470 - val_accuracy: 0.3598\nEpoch 8/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7598 - accuracy: 0.3582 - val_loss: 1.7480 - val_accuracy: 0.3594\nEpoch 9/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7556 - accuracy: 0.3598 - val_loss: 1.7472 - val_accuracy: 0.3602\n\nEpoch 00009: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\nEpoch 10/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7520 - accuracy: 0.3619 - val_loss: 1.7467 - val_accuracy: 0.3605\nEpoch 11/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7538 - accuracy: 0.3604 - val_loss: 1.7474 - val_accuracy: 0.3601\nEpoch 12/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7500 - accuracy: 0.3626 - val_loss: 1.7481 - val_accuracy: 0.3594\n\nEpoch 00012: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 13/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7502 - accuracy: 0.3599 - val_loss: 1.7476 - val_accuracy: 0.3594\nEpoch 14/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7546 - accuracy: 0.3590 - val_loss: 1.7478 - val_accuracy: 0.3589\n\nEpoch 00014: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 15/100\n 874/1500 [================>.............] - ETA: 2s - loss: 1.7529 - accuracy: 0.3591","output_type":"stream"},{"text":"IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n","name":"stderr","output_type":"stream"},{"name":"stdout","text":"1500/1500 [==============================] - 7s 4ms/step - loss: 1.7470 - accuracy: 0.3632 - val_loss: 1.7478 - val_accuracy: 0.3610\n[[0.0563662  0.36440033 0.14215032 ... 0.01902249 0.03907217 0.10952622]\n [0.03853353 0.05423631 0.04393861 ... 0.07778921 0.2758651  0.11262983]\n [0.01608691 0.02122794 0.01429362 ... 0.02012437 0.09096558 0.03592742]\n ...\n [0.05016784 0.203499   0.11145187 ... 0.04576589 0.11713625 0.14238273]\n [0.03123622 0.02173324 0.01929833 ... 0.07304005 0.33349496 0.07750954]\n [0.04158961 0.08168251 0.06283435 ... 0.07390564 0.2206966  0.12687863]]\nLogloss: 1.74669\nEpoch 1/100\n1500/1500 [==============================] - 8s 5ms/step - loss: 2.3274 - accuracy: 0.2194 - val_loss: 1.7923 - val_accuracy: 0.3661\nEpoch 2/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.8478 - accuracy: 0.3344 - val_loss: 1.7475 - val_accuracy: 0.3708\nEpoch 3/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7920 - accuracy: 0.3461 - val_loss: 1.7427 - val_accuracy: 0.3716\nEpoch 4/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7744 - accuracy: 0.3538 - val_loss: 1.7416 - val_accuracy: 0.3749\nEpoch 5/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7684 - accuracy: 0.3575 - val_loss: 1.7412 - val_accuracy: 0.3731\nEpoch 6/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7616 - accuracy: 0.3571 - val_loss: 1.7391 - val_accuracy: 0.3728\nEpoch 7/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7583 - accuracy: 0.3599 - val_loss: 1.7403 - val_accuracy: 0.3720\nEpoch 8/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7601 - accuracy: 0.3595 - val_loss: 1.7391 - val_accuracy: 0.3729\n\nEpoch 00008: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\nEpoch 9/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7547 - accuracy: 0.3603 - val_loss: 1.7368 - val_accuracy: 0.3745\nEpoch 10/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7510 - accuracy: 0.3620 - val_loss: 1.7365 - val_accuracy: 0.3735\nEpoch 11/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7566 - accuracy: 0.3590 - val_loss: 1.7370 - val_accuracy: 0.3742\nEpoch 12/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7506 - accuracy: 0.3614 - val_loss: 1.7370 - val_accuracy: 0.3744\n\nEpoch 00012: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 13/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7500 - accuracy: 0.3599 - val_loss: 1.7370 - val_accuracy: 0.3760\nEpoch 14/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7568 - accuracy: 0.3583 - val_loss: 1.7371 - val_accuracy: 0.3742\n\nEpoch 00014: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 15/100\n1500/1500 [==============================] - 6s 4ms/step - loss: 1.7538 - accuracy: 0.3604 - val_loss: 1.7372 - val_accuracy: 0.3736\nEpoch 16/100\n1500/1500 [==============================] - 9s 6ms/step - loss: 1.7516 - accuracy: 0.3599 - val_loss: 1.7372 - val_accuracy: 0.3738\n\nEpoch 00016: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\nEpoch 17/100\n1500/1500 [==============================] - 11s 7ms/step - loss: 1.7509 - accuracy: 0.3599 - val_loss: 1.7369 - val_accuracy: 0.3742\nEpoch 18/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7512 - accuracy: 0.3627 - val_loss: 1.7368 - val_accuracy: 0.3747\n\nEpoch 00018: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\nEpoch 19/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7473 - accuracy: 0.3620 - val_loss: 1.7368 - val_accuracy: 0.3749\nEpoch 20/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7502 - accuracy: 0.3594 - val_loss: 1.7370 - val_accuracy: 0.3754\n\nEpoch 00020: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\nEpoch 21/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7508 - accuracy: 0.3618 - val_loss: 1.7369 - val_accuracy: 0.3746\nEpoch 22/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7520 - accuracy: 0.3615 - val_loss: 1.7369 - val_accuracy: 0.3746\n\nEpoch 00022: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\nEpoch 23/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7498 - accuracy: 0.3622 - val_loss: 1.7368 - val_accuracy: 0.3746\nEpoch 24/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7502 - accuracy: 0.3629 - val_loss: 1.7369 - val_accuracy: 0.3745\n\nEpoch 00024: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\nEpoch 25/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7493 - accuracy: 0.3634 - val_loss: 1.7369 - val_accuracy: 0.3747\n[[0.05884086 0.38023828 0.14861293 ... 0.01995466 0.04100267 0.11472686]\n [0.04019427 0.05645248 0.04575038 ... 0.08137976 0.28896734 0.11753175]\n [0.01675386 0.02198362 0.01485357 ... 0.02113134 0.09532243 0.03750969]\n ...\n [0.05241953 0.2124541  0.11647411 ... 0.04794224 0.12272389 0.14894336]\n [0.03259932 0.02265037 0.02008336 ... 0.07639285 0.3485724  0.08085865]\n [0.04343349 0.08516196 0.06554515 ... 0.07737175 0.23117133 0.13253003]]\nLogloss: 1.73653\nEpoch 1/100\n1500/1500 [==============================] - 8s 5ms/step - loss: 2.3820 - accuracy: 0.2113 - val_loss: 1.7972 - val_accuracy: 0.3528\nEpoch 2/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.8574 - accuracy: 0.3328 - val_loss: 1.7548 - val_accuracy: 0.3584\nEpoch 3/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7973 - accuracy: 0.3466 - val_loss: 1.7514 - val_accuracy: 0.3607\nEpoch 4/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7771 - accuracy: 0.3566 - val_loss: 1.7492 - val_accuracy: 0.3593\nEpoch 5/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7714 - accuracy: 0.3549 - val_loss: 1.7465 - val_accuracy: 0.3624\nEpoch 6/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7644 - accuracy: 0.3569 - val_loss: 1.7465 - val_accuracy: 0.3645\nEpoch 7/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7612 - accuracy: 0.3579 - val_loss: 1.7443 - val_accuracy: 0.3626\nEpoch 8/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7608 - accuracy: 0.3586 - val_loss: 1.7438 - val_accuracy: 0.3609\nEpoch 9/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7577 - accuracy: 0.3600 - val_loss: 1.7429 - val_accuracy: 0.3610\nEpoch 10/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7552 - accuracy: 0.3605 - val_loss: 1.7431 - val_accuracy: 0.3631\nEpoch 11/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7580 - accuracy: 0.3582 - val_loss: 1.7428 - val_accuracy: 0.3635\nEpoch 12/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7532 - accuracy: 0.3618 - val_loss: 1.7420 - val_accuracy: 0.3655\nEpoch 13/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7527 - accuracy: 0.3582 - val_loss: 1.7421 - val_accuracy: 0.3625\nEpoch 14/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7579 - accuracy: 0.3584 - val_loss: 1.7444 - val_accuracy: 0.3640\n\nEpoch 00014: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\nEpoch 15/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7543 - accuracy: 0.3603 - val_loss: 1.7419 - val_accuracy: 0.3638\nEpoch 16/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7512 - accuracy: 0.3604 - val_loss: 1.7419 - val_accuracy: 0.3644\nEpoch 17/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7505 - accuracy: 0.3605 - val_loss: 1.7417 - val_accuracy: 0.3630\nEpoch 18/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7514 - accuracy: 0.3626 - val_loss: 1.7417 - val_accuracy: 0.3619\nEpoch 19/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7468 - accuracy: 0.3642 - val_loss: 1.7425 - val_accuracy: 0.3632\n\nEpoch 00019: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 20/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7494 - accuracy: 0.3606 - val_loss: 1.7420 - val_accuracy: 0.3631\nEpoch 21/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7500 - accuracy: 0.3609 - val_loss: 1.7428 - val_accuracy: 0.3643\n\nEpoch 00021: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 22/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7499 - accuracy: 0.3623 - val_loss: 1.7422 - val_accuracy: 0.3625\nEpoch 23/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7483 - accuracy: 0.3632 - val_loss: 1.7419 - val_accuracy: 0.3640\n\nEpoch 00023: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\nEpoch 24/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7478 - accuracy: 0.3632 - val_loss: 1.7421 - val_accuracy: 0.3635\nEpoch 25/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7455 - accuracy: 0.3660 - val_loss: 1.7420 - val_accuracy: 0.3631\n\nEpoch 00025: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\nEpoch 26/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7461 - accuracy: 0.3634 - val_loss: 1.7420 - val_accuracy: 0.3640\nEpoch 27/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7481 - accuracy: 0.3633 - val_loss: 1.7419 - val_accuracy: 0.3634\n\nEpoch 00027: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\nEpoch 28/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7442 - accuracy: 0.3636 - val_loss: 1.7420 - val_accuracy: 0.3641\nEpoch 29/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7511 - accuracy: 0.3616 - val_loss: 1.7419 - val_accuracy: 0.3635\n\nEpoch 00029: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\nEpoch 30/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7442 - accuracy: 0.3634 - val_loss: 1.7419 - val_accuracy: 0.3644\nEpoch 31/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7524 - accuracy: 0.3587 - val_loss: 1.7419 - val_accuracy: 0.3641\n\nEpoch 00031: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\nEpoch 32/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7476 - accuracy: 0.3629 - val_loss: 1.7418 - val_accuracy: 0.3638\n[[0.06133849 0.39653424 0.15490685 ... 0.02087981 0.0430005  0.11974415]\n [0.04192044 0.05911777 0.04793277 ... 0.08493524 0.30132331 0.12294555]\n [0.0175545  0.02298037 0.01555899 ... 0.02212941 0.09973813 0.03922107]\n ...\n [0.05471189 0.22318141 0.12171699 ... 0.04973832 0.12743884 0.15515846]\n [0.03383838 0.02352605 0.02086297 ... 0.07945927 0.36412782 0.08410186]\n [0.04530451 0.08864657 0.06836537 ... 0.08088523 0.24117317 0.13844686]]\nLogloss: 1.74171\nEpoch 1/100\n1500/1500 [==============================] - 8s 5ms/step - loss: 2.3945 - accuracy: 0.2075 - val_loss: 1.7845 - val_accuracy: 0.3576\nEpoch 2/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.8542 - accuracy: 0.3341 - val_loss: 1.7505 - val_accuracy: 0.3643\nEpoch 3/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7956 - accuracy: 0.3469 - val_loss: 1.7467 - val_accuracy: 0.3651\nEpoch 4/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7772 - accuracy: 0.3559 - val_loss: 1.7436 - val_accuracy: 0.3669\nEpoch 5/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7701 - accuracy: 0.3571 - val_loss: 1.7427 - val_accuracy: 0.3672\nEpoch 6/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7657 - accuracy: 0.3585 - val_loss: 1.7415 - val_accuracy: 0.3655\nEpoch 7/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7609 - accuracy: 0.3578 - val_loss: 1.7414 - val_accuracy: 0.3671\nEpoch 8/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7605 - accuracy: 0.3583 - val_loss: 1.7408 - val_accuracy: 0.3674\nEpoch 9/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7568 - accuracy: 0.3594 - val_loss: 1.7403 - val_accuracy: 0.3680\nEpoch 10/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7537 - accuracy: 0.3619 - val_loss: 1.7407 - val_accuracy: 0.3676\nEpoch 11/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7597 - accuracy: 0.3584 - val_loss: 1.7403 - val_accuracy: 0.3645\n\nEpoch 00011: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\nEpoch 12/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7507 - accuracy: 0.3623 - val_loss: 1.7409 - val_accuracy: 0.3683\nEpoch 13/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7504 - accuracy: 0.3595 - val_loss: 1.7397 - val_accuracy: 0.3671\nEpoch 14/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7572 - accuracy: 0.3592 - val_loss: 1.7405 - val_accuracy: 0.3696\nEpoch 15/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7534 - accuracy: 0.3609 - val_loss: 1.7399 - val_accuracy: 0.3674\n\nEpoch 00015: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 16/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7503 - accuracy: 0.3617 - val_loss: 1.7400 - val_accuracy: 0.3684\nEpoch 17/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7496 - accuracy: 0.3615 - val_loss: 1.7400 - val_accuracy: 0.3690\n\nEpoch 00017: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 18/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7500 - accuracy: 0.3642 - val_loss: 1.7403 - val_accuracy: 0.3689\nEpoch 19/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7461 - accuracy: 0.3651 - val_loss: 1.7400 - val_accuracy: 0.3688\n\nEpoch 00019: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\nEpoch 20/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7485 - accuracy: 0.3607 - val_loss: 1.7402 - val_accuracy: 0.3683\nEpoch 21/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7501 - accuracy: 0.3601 - val_loss: 1.7401 - val_accuracy: 0.3690\n\nEpoch 00021: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\nEpoch 22/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7504 - accuracy: 0.3627 - val_loss: 1.7401 - val_accuracy: 0.3686\nEpoch 23/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7478 - accuracy: 0.3629 - val_loss: 1.7400 - val_accuracy: 0.3688\n\nEpoch 00023: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\nEpoch 24/100\n1500/1500 [==============================] - 7s 4ms/step - loss: 1.7485 - accuracy: 0.3630 - val_loss: 1.7402 - val_accuracy: 0.3684\nEpoch 25/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7468 - accuracy: 0.3652 - val_loss: 1.7402 - val_accuracy: 0.3683\n\nEpoch 00025: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\nEpoch 26/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7466 - accuracy: 0.3631 - val_loss: 1.7402 - val_accuracy: 0.3686\nEpoch 27/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7503 - accuracy: 0.3625 - val_loss: 1.7401 - val_accuracy: 0.3686\n\nEpoch 00027: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\nEpoch 28/100\n1500/1500 [==============================] - 7s 5ms/step - loss: 1.7451 - accuracy: 0.3640 - val_loss: 1.7402 - val_accuracy: 0.3684\n[[0.06402962 0.41301513 0.16118892 ... 0.02174677 0.0447529  0.12475989]\n [0.04368158 0.06203724 0.05025035 ... 0.08842177 0.31305522 0.12847868]\n [0.0181821  0.02376786 0.01604034 ... 0.02278133 0.10272309 0.04048747]\n ...\n [0.05702183 0.2323623  0.12670408 ... 0.05174331 0.13250377 0.16146766]\n [0.03519911 0.02450641 0.02168122 ... 0.0827277  0.37944414 0.08753943]\n [0.04716504 0.09271164 0.07147664 ... 0.08414337 0.25072737 0.14438803]]\nLogloss: 1.73973\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Logloss: {0:0.6f}\".format(metrics.log_loss(Y_train,train_oof)))\n#10 folds - Logloss: 1.744198","metadata":{"execution":{"iopub.status.busy":"2021-09-01T10:08:53.745428Z","iopub.execute_input":"2021-09-01T10:08:53.745833Z","iopub.status.idle":"2021-09-01T10:08:53.856531Z","shell.execute_reply.started":"2021-09-01T10:08:53.745788Z","shell.execute_reply":"2021-09-01T10:08:53.855680Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Logloss: 1.742429\n","output_type":"stream"}]},{"cell_type":"code","source":"train_oof = pd.DataFrame(train_oof, columns = ['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9'])\ntrain_oof","metadata":{"execution":{"iopub.status.busy":"2021-09-01T10:08:53.857905Z","iopub.execute_input":"2021-09-01T10:08:53.858262Z","iopub.status.idle":"2021-09-01T10:08:53.881843Z","shell.execute_reply.started":"2021-09-01T10:08:53.858224Z","shell.execute_reply":"2021-09-01T10:08:53.880736Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"         Class_1   Class_2   Class_3   Class_4   Class_5   Class_6   Class_7  \\\n0       0.013138  0.016654  0.010073  0.005021  0.002380  0.822062  0.017013   \n1       0.028262  0.086573  0.053934  0.014021  0.005970  0.554876  0.034900   \n2       0.049328  0.098643  0.074622  0.028713  0.020412  0.164242  0.097278   \n3       0.054119  0.114563  0.084527  0.031580  0.023065  0.114002  0.099741   \n4       0.063916  0.289851  0.145289  0.033122  0.018039  0.152968  0.042628   \n...          ...       ...       ...       ...       ...       ...       ...   \n199995  0.045294  0.073763  0.061028  0.025580  0.017640  0.254750  0.090388   \n199996  0.040188  0.089291  0.069572  0.022853  0.015051  0.285341  0.077601   \n199997  0.043908  0.049405  0.042699  0.019793  0.015914  0.275616  0.093599   \n199998  0.042330  0.087449  0.071807  0.025666  0.018192  0.277381  0.080868   \n199999  0.037506  0.025668  0.021033  0.013210  0.009462  0.324743  0.083998   \n\n         Class_8   Class_9  \n0       0.084409  0.029252  \n1       0.129713  0.091750  \n2       0.313202  0.153561  \n3       0.317676  0.160727  \n4       0.098629  0.155558  \n...          ...       ...  \n199995  0.291198  0.140359  \n199996  0.255882  0.144222  \n199997  0.335370  0.123697  \n199998  0.252885  0.143422  \n199999  0.395088  0.089291  \n\n[200000 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Class_1</th>\n      <th>Class_2</th>\n      <th>Class_3</th>\n      <th>Class_4</th>\n      <th>Class_5</th>\n      <th>Class_6</th>\n      <th>Class_7</th>\n      <th>Class_8</th>\n      <th>Class_9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.013138</td>\n      <td>0.016654</td>\n      <td>0.010073</td>\n      <td>0.005021</td>\n      <td>0.002380</td>\n      <td>0.822062</td>\n      <td>0.017013</td>\n      <td>0.084409</td>\n      <td>0.029252</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.028262</td>\n      <td>0.086573</td>\n      <td>0.053934</td>\n      <td>0.014021</td>\n      <td>0.005970</td>\n      <td>0.554876</td>\n      <td>0.034900</td>\n      <td>0.129713</td>\n      <td>0.091750</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.049328</td>\n      <td>0.098643</td>\n      <td>0.074622</td>\n      <td>0.028713</td>\n      <td>0.020412</td>\n      <td>0.164242</td>\n      <td>0.097278</td>\n      <td>0.313202</td>\n      <td>0.153561</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.054119</td>\n      <td>0.114563</td>\n      <td>0.084527</td>\n      <td>0.031580</td>\n      <td>0.023065</td>\n      <td>0.114002</td>\n      <td>0.099741</td>\n      <td>0.317676</td>\n      <td>0.160727</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.063916</td>\n      <td>0.289851</td>\n      <td>0.145289</td>\n      <td>0.033122</td>\n      <td>0.018039</td>\n      <td>0.152968</td>\n      <td>0.042628</td>\n      <td>0.098629</td>\n      <td>0.155558</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>199995</th>\n      <td>0.045294</td>\n      <td>0.073763</td>\n      <td>0.061028</td>\n      <td>0.025580</td>\n      <td>0.017640</td>\n      <td>0.254750</td>\n      <td>0.090388</td>\n      <td>0.291198</td>\n      <td>0.140359</td>\n    </tr>\n    <tr>\n      <th>199996</th>\n      <td>0.040188</td>\n      <td>0.089291</td>\n      <td>0.069572</td>\n      <td>0.022853</td>\n      <td>0.015051</td>\n      <td>0.285341</td>\n      <td>0.077601</td>\n      <td>0.255882</td>\n      <td>0.144222</td>\n    </tr>\n    <tr>\n      <th>199997</th>\n      <td>0.043908</td>\n      <td>0.049405</td>\n      <td>0.042699</td>\n      <td>0.019793</td>\n      <td>0.015914</td>\n      <td>0.275616</td>\n      <td>0.093599</td>\n      <td>0.335370</td>\n      <td>0.123697</td>\n    </tr>\n    <tr>\n      <th>199998</th>\n      <td>0.042330</td>\n      <td>0.087449</td>\n      <td>0.071807</td>\n      <td>0.025666</td>\n      <td>0.018192</td>\n      <td>0.277381</td>\n      <td>0.080868</td>\n      <td>0.252885</td>\n      <td>0.143422</td>\n    </tr>\n    <tr>\n      <th>199999</th>\n      <td>0.037506</td>\n      <td>0.025668</td>\n      <td>0.021033</td>\n      <td>0.013210</td>\n      <td>0.009462</td>\n      <td>0.324743</td>\n      <td>0.083998</td>\n      <td>0.395088</td>\n      <td>0.089291</td>\n    </tr>\n  </tbody>\n</table>\n<p>200000 rows × 9 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"pred_test = pd.DataFrame(nn_pred, columns = ['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9'])\npred_test","metadata":{"execution":{"iopub.status.busy":"2021-09-01T10:08:53.883559Z","iopub.execute_input":"2021-09-01T10:08:53.883954Z","iopub.status.idle":"2021-09-01T10:08:53.902992Z","shell.execute_reply.started":"2021-09-01T10:08:53.883894Z","shell.execute_reply":"2021-09-01T10:08:53.901798Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"        Class_1   Class_2   Class_3   Class_4   Class_5   Class_6   Class_7  \\\n0      0.064030  0.413015  0.161189  0.027990  0.013462  0.129054  0.021747   \n1      0.043682  0.062037  0.050250  0.021710  0.015264  0.277101  0.088422   \n2      0.018182  0.023768  0.016040  0.007913  0.004050  0.764054  0.022781   \n3      0.048610  0.134867  0.092336  0.030470  0.018496  0.227544  0.075415   \n4      0.044383  0.113068  0.081460  0.026674  0.016311  0.275291  0.072400   \n...         ...       ...       ...       ...       ...       ...       ...   \n99995  0.063865  0.353068  0.161613  0.032219  0.016906  0.102752  0.037230   \n99996  0.056481  0.244369  0.134149  0.031802  0.017032  0.151330  0.055064   \n99997  0.057022  0.232362  0.126704  0.031464  0.016926  0.189808  0.051743   \n99998  0.035199  0.024506  0.021681  0.012528  0.009446  0.346928  0.082728   \n99999  0.047165  0.092712  0.071477  0.028570  0.019348  0.261469  0.084143   \n\n        Class_8   Class_9  \n0      0.044753  0.124760  \n1      0.313055  0.128479  \n2      0.102723  0.040487  \n3      0.213077  0.159183  \n4      0.221608  0.148808  \n...         ...       ...  \n99995  0.081725  0.150623  \n99996  0.142823  0.166952  \n99997  0.132504  0.161468  \n99998  0.379444  0.087539  \n99999  0.250727  0.144388  \n\n[100000 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Class_1</th>\n      <th>Class_2</th>\n      <th>Class_3</th>\n      <th>Class_4</th>\n      <th>Class_5</th>\n      <th>Class_6</th>\n      <th>Class_7</th>\n      <th>Class_8</th>\n      <th>Class_9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.064030</td>\n      <td>0.413015</td>\n      <td>0.161189</td>\n      <td>0.027990</td>\n      <td>0.013462</td>\n      <td>0.129054</td>\n      <td>0.021747</td>\n      <td>0.044753</td>\n      <td>0.124760</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.043682</td>\n      <td>0.062037</td>\n      <td>0.050250</td>\n      <td>0.021710</td>\n      <td>0.015264</td>\n      <td>0.277101</td>\n      <td>0.088422</td>\n      <td>0.313055</td>\n      <td>0.128479</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.018182</td>\n      <td>0.023768</td>\n      <td>0.016040</td>\n      <td>0.007913</td>\n      <td>0.004050</td>\n      <td>0.764054</td>\n      <td>0.022781</td>\n      <td>0.102723</td>\n      <td>0.040487</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.048610</td>\n      <td>0.134867</td>\n      <td>0.092336</td>\n      <td>0.030470</td>\n      <td>0.018496</td>\n      <td>0.227544</td>\n      <td>0.075415</td>\n      <td>0.213077</td>\n      <td>0.159183</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.044383</td>\n      <td>0.113068</td>\n      <td>0.081460</td>\n      <td>0.026674</td>\n      <td>0.016311</td>\n      <td>0.275291</td>\n      <td>0.072400</td>\n      <td>0.221608</td>\n      <td>0.148808</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>99995</th>\n      <td>0.063865</td>\n      <td>0.353068</td>\n      <td>0.161613</td>\n      <td>0.032219</td>\n      <td>0.016906</td>\n      <td>0.102752</td>\n      <td>0.037230</td>\n      <td>0.081725</td>\n      <td>0.150623</td>\n    </tr>\n    <tr>\n      <th>99996</th>\n      <td>0.056481</td>\n      <td>0.244369</td>\n      <td>0.134149</td>\n      <td>0.031802</td>\n      <td>0.017032</td>\n      <td>0.151330</td>\n      <td>0.055064</td>\n      <td>0.142823</td>\n      <td>0.166952</td>\n    </tr>\n    <tr>\n      <th>99997</th>\n      <td>0.057022</td>\n      <td>0.232362</td>\n      <td>0.126704</td>\n      <td>0.031464</td>\n      <td>0.016926</td>\n      <td>0.189808</td>\n      <td>0.051743</td>\n      <td>0.132504</td>\n      <td>0.161468</td>\n    </tr>\n    <tr>\n      <th>99998</th>\n      <td>0.035199</td>\n      <td>0.024506</td>\n      <td>0.021681</td>\n      <td>0.012528</td>\n      <td>0.009446</td>\n      <td>0.346928</td>\n      <td>0.082728</td>\n      <td>0.379444</td>\n      <td>0.087539</td>\n    </tr>\n    <tr>\n      <th>99999</th>\n      <td>0.047165</td>\n      <td>0.092712</td>\n      <td>0.071477</td>\n      <td>0.028570</td>\n      <td>0.019348</td>\n      <td>0.261469</td>\n      <td>0.084143</td>\n      <td>0.250727</td>\n      <td>0.144388</td>\n    </tr>\n  </tbody>\n</table>\n<p>100000 rows × 9 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_oof.to_csv('nn_train_oof.csv', index=False)\ntrain_oof","metadata":{"execution":{"iopub.status.busy":"2021-09-01T10:08:53.904901Z","iopub.execute_input":"2021-09-01T10:08:53.905677Z","iopub.status.idle":"2021-09-01T10:08:58.276503Z","shell.execute_reply.started":"2021-09-01T10:08:53.905635Z","shell.execute_reply":"2021-09-01T10:08:58.275589Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"         Class_1   Class_2   Class_3   Class_4   Class_5   Class_6   Class_7  \\\n0       0.013138  0.016654  0.010073  0.005021  0.002380  0.822062  0.017013   \n1       0.028262  0.086573  0.053934  0.014021  0.005970  0.554876  0.034900   \n2       0.049328  0.098643  0.074622  0.028713  0.020412  0.164242  0.097278   \n3       0.054119  0.114563  0.084527  0.031580  0.023065  0.114002  0.099741   \n4       0.063916  0.289851  0.145289  0.033122  0.018039  0.152968  0.042628   \n...          ...       ...       ...       ...       ...       ...       ...   \n199995  0.045294  0.073763  0.061028  0.025580  0.017640  0.254750  0.090388   \n199996  0.040188  0.089291  0.069572  0.022853  0.015051  0.285341  0.077601   \n199997  0.043908  0.049405  0.042699  0.019793  0.015914  0.275616  0.093599   \n199998  0.042330  0.087449  0.071807  0.025666  0.018192  0.277381  0.080868   \n199999  0.037506  0.025668  0.021033  0.013210  0.009462  0.324743  0.083998   \n\n         Class_8   Class_9  \n0       0.084409  0.029252  \n1       0.129713  0.091750  \n2       0.313202  0.153561  \n3       0.317676  0.160727  \n4       0.098629  0.155558  \n...          ...       ...  \n199995  0.291198  0.140359  \n199996  0.255882  0.144222  \n199997  0.335370  0.123697  \n199998  0.252885  0.143422  \n199999  0.395088  0.089291  \n\n[200000 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Class_1</th>\n      <th>Class_2</th>\n      <th>Class_3</th>\n      <th>Class_4</th>\n      <th>Class_5</th>\n      <th>Class_6</th>\n      <th>Class_7</th>\n      <th>Class_8</th>\n      <th>Class_9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.013138</td>\n      <td>0.016654</td>\n      <td>0.010073</td>\n      <td>0.005021</td>\n      <td>0.002380</td>\n      <td>0.822062</td>\n      <td>0.017013</td>\n      <td>0.084409</td>\n      <td>0.029252</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.028262</td>\n      <td>0.086573</td>\n      <td>0.053934</td>\n      <td>0.014021</td>\n      <td>0.005970</td>\n      <td>0.554876</td>\n      <td>0.034900</td>\n      <td>0.129713</td>\n      <td>0.091750</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.049328</td>\n      <td>0.098643</td>\n      <td>0.074622</td>\n      <td>0.028713</td>\n      <td>0.020412</td>\n      <td>0.164242</td>\n      <td>0.097278</td>\n      <td>0.313202</td>\n      <td>0.153561</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.054119</td>\n      <td>0.114563</td>\n      <td>0.084527</td>\n      <td>0.031580</td>\n      <td>0.023065</td>\n      <td>0.114002</td>\n      <td>0.099741</td>\n      <td>0.317676</td>\n      <td>0.160727</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.063916</td>\n      <td>0.289851</td>\n      <td>0.145289</td>\n      <td>0.033122</td>\n      <td>0.018039</td>\n      <td>0.152968</td>\n      <td>0.042628</td>\n      <td>0.098629</td>\n      <td>0.155558</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>199995</th>\n      <td>0.045294</td>\n      <td>0.073763</td>\n      <td>0.061028</td>\n      <td>0.025580</td>\n      <td>0.017640</td>\n      <td>0.254750</td>\n      <td>0.090388</td>\n      <td>0.291198</td>\n      <td>0.140359</td>\n    </tr>\n    <tr>\n      <th>199996</th>\n      <td>0.040188</td>\n      <td>0.089291</td>\n      <td>0.069572</td>\n      <td>0.022853</td>\n      <td>0.015051</td>\n      <td>0.285341</td>\n      <td>0.077601</td>\n      <td>0.255882</td>\n      <td>0.144222</td>\n    </tr>\n    <tr>\n      <th>199997</th>\n      <td>0.043908</td>\n      <td>0.049405</td>\n      <td>0.042699</td>\n      <td>0.019793</td>\n      <td>0.015914</td>\n      <td>0.275616</td>\n      <td>0.093599</td>\n      <td>0.335370</td>\n      <td>0.123697</td>\n    </tr>\n    <tr>\n      <th>199998</th>\n      <td>0.042330</td>\n      <td>0.087449</td>\n      <td>0.071807</td>\n      <td>0.025666</td>\n      <td>0.018192</td>\n      <td>0.277381</td>\n      <td>0.080868</td>\n      <td>0.252885</td>\n      <td>0.143422</td>\n    </tr>\n    <tr>\n      <th>199999</th>\n      <td>0.037506</td>\n      <td>0.025668</td>\n      <td>0.021033</td>\n      <td>0.013210</td>\n      <td>0.009462</td>\n      <td>0.324743</td>\n      <td>0.083998</td>\n      <td>0.395088</td>\n      <td>0.089291</td>\n    </tr>\n  </tbody>\n</table>\n<p>200000 rows × 9 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"output = pred_test\noutput['id'] = X_test.index\noutput.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T10:08:58.277953Z","iopub.execute_input":"2021-09-01T10:08:58.278338Z","iopub.status.idle":"2021-09-01T10:09:00.317862Z","shell.execute_reply.started":"2021-09-01T10:08:58.278297Z","shell.execute_reply":"2021-09-01T10:09:00.317016Z"},"trusted":true},"execution_count":20,"outputs":[]}]}